{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Run_Davidson_SSDA.ipynb","provenance":[{"file_id":"1D6krVG0PPJR2Je9g5eN_2h6JP73_NUXz","timestamp":1617304009738},{"file_id":"1d_7axqPO6iSbI6joKb5EAFKV2rPmXt6X","timestamp":1616054665801}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a0afce0b0c8b454a8a3b9c01a74f644f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_30e269680eaa463f90649ce94cfbb6f3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_223267c9995241e9aaef9f317a6fa043","IPY_MODEL_665e0db88099495c959ce32e91280c95"]}},"30e269680eaa463f90649ce94cfbb6f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"223267c9995241e9aaef9f317a6fa043":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9d0b233ebc6a40f992beb95692fd0112","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":1857,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1857,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_180ed9c342c24e768001fa3603001855"}},"665e0db88099495c959ce32e91280c95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2383f3c5f7be40dcb7790f5b20cc9183","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.85k/? [00:00&lt;00:00, 16.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1c484f8cc9e42768fced4bfdd3c4aa8"}},"9d0b233ebc6a40f992beb95692fd0112":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"180ed9c342c24e768001fa3603001855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2383f3c5f7be40dcb7790f5b20cc9183":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1c484f8cc9e42768fced4bfdd3c4aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a840cead5109421a8c902950af588345":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_596bee1cd68a4a3dab2bbaceefaf589f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5d503ce4862c4ba3aebe93c697c0452f","IPY_MODEL_ffc06a0a6afb416b814587239cc49174"]}},"596bee1cd68a4a3dab2bbaceefaf589f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d503ce4862c4ba3aebe93c697c0452f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1f3a417cee7142c0ad0c1882168af883","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":1131,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1131,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d00089977ffe48ac9732ee683fa031b5"}},"ffc06a0a6afb416b814587239cc49174":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef4517977365478381ae999357bf4fbf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.75k/? [00:02&lt;00:00, 1.19kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a8987eff745b447d9fd8aa4c81426a4e"}},"1f3a417cee7142c0ad0c1882168af883":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d00089977ffe48ac9732ee683fa031b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef4517977365478381ae999357bf4fbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a8987eff745b447d9fd8aa4c81426a4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e577de800c54f2b9181810eade80a0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_63cf875e29f9434b80a9c4290ceae42c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4e04f5edef2459aad41f95ef1046159","IPY_MODEL_b5b603651c92420484f108fd2e2d8753"]}},"63cf875e29f9434b80a9c4290ceae42c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4e04f5edef2459aad41f95ef1046159":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1324b22c46e3422486d7707f9d6f9ea6","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":2028297,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2028297,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a967fa4807e94be0bd61a3796bb3c821"}},"b5b603651c92420484f108fd2e2d8753":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5cd2d857ec494397aae2494bdb8d444e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 12.3M/? [00:00&lt;00:00, 21.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_26d6f1f2931a4e24837ecf005fd29399"}},"1324b22c46e3422486d7707f9d6f9ea6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a967fa4807e94be0bd61a3796bb3c821":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cd2d857ec494397aae2494bdb8d444e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"26d6f1f2931a4e24837ecf005fd29399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee70602f67cb4cb0b602827e97a120b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_44e4370189ca4bc9ae9d457f2b646f97","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b2b15a62e5c04c438572614749fc33b5","IPY_MODEL_957c89ea613f4c20ab99cfe41da0806a"]}},"44e4370189ca4bc9ae9d457f2b646f97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2b15a62e5c04c438572614749fc33b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a8416b767b834698a0ef17de794bb06c","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":145439,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":145439,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_697563f9972d4bdf853298f0b6e23617"}},"957c89ea613f4c20ab99cfe41da0806a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a2cb8710d3554023b28ac2f8c04cc3c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 592k/? [00:00&lt;00:00, 4.76MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_482b8aa0249146dca1046ea80107f726"}},"a8416b767b834698a0ef17de794bb06c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"697563f9972d4bdf853298f0b6e23617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2cb8710d3554023b28ac2f8c04cc3c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"482b8aa0249146dca1046ea80107f726":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d03d0a9f9d2e4c0fb20aba0a22c077ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bc3f51b0b9dd4972887aa6e8fe69eb07","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4511f31581d45e287ce626b151eabf0","IPY_MODEL_7f582d91a3d64cdd86b69ddff3e86028"]}},"bc3f51b0b9dd4972887aa6e8fe69eb07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4511f31581d45e287ce626b151eabf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4809a43104af458ea27eff813ea2d718","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_374a7fe7624a4908b683bf8075c84ba9"}},"7f582d91a3d64cdd86b69ddff3e86028":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e21817befed48caa3dc18080c50f136","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15383/0 [00:04&lt;00:00, 4734.83 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3992ba274eb47e5bb5450909c0b88ef"}},"4809a43104af458ea27eff813ea2d718":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"374a7fe7624a4908b683bf8075c84ba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e21817befed48caa3dc18080c50f136":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f3992ba274eb47e5bb5450909c0b88ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7848a813969248cfb8faea96eac25c27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d919f00c597e4075b11dbc995c47dcee","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fbafc9f6b3304ab28ad9b42cb024195e","IPY_MODEL_34f82d4727874c758954db198edb4314"]}},"d919f00c597e4075b11dbc995c47dcee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbafc9f6b3304ab28ad9b42cb024195e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b6568ee85ca445f18f8a9d338ddc11cc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38505dc1dfdc40bd87b54e3354c5d88c"}},"34f82d4727874c758954db198edb4314":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_892b236d394e4e948e793fd09bffe78f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1922/0 [00:01&lt;00:00,  3.97 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6e13d6a5038431fab29f34c46c982f3"}},"b6568ee85ca445f18f8a9d338ddc11cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"38505dc1dfdc40bd87b54e3354c5d88c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"892b236d394e4e948e793fd09bffe78f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b6e13d6a5038431fab29f34c46c982f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0946beb202c4bbdbbbbb4b056ca437e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f47bba9738054ba0b7c1f796e37a3aec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9a7bdc6b01c94ff1adf4e8e581daaaf9","IPY_MODEL_a7ff35a74e45420e8e75dbc6a53ef289"]}},"f47bba9738054ba0b7c1f796e37a3aec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a7bdc6b01c94ff1adf4e8e581daaaf9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4a6e4484deb445789673b12fae1593c6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9dc23a51d0a245f795c1d6bfa6c6138a"}},"a7ff35a74e45420e8e75dbc6a53ef289":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0a24d5dcb724293b17aa0d4d9f3aa94","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1924/0 [00:01&lt;00:00,  5.74 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f23ad992e694878a016c64c4bc26f86"}},"4a6e4484deb445789673b12fae1593c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9dc23a51d0a245f795c1d6bfa6c6138a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0a24d5dcb724293b17aa0d4d9f3aa94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6f23ad992e694878a016c64c4bc26f86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8315d9d057d0457094670cb410bd13c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_997fadf0f1c14e909e0c3013ab966c58","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74d384be1f594cc999e207d368459e23","IPY_MODEL_f0f715aa6a3e4baa98c402c9a6b52d54"]}},"997fadf0f1c14e909e0c3013ab966c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74d384be1f594cc999e207d368459e23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b88d19f438d946ebb5ea0bf74ad16fc7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a2607a0bbac48b09922e8847ebca61c"}},"f0f715aa6a3e4baa98c402c9a6b52d54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c92ed80c2a94434faddb653f2e319198","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [02:17&lt;00:00, 3.16B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f6ab60d5931f4e8cb4eb5df572496d5e"}},"b88d19f438d946ebb5ea0bf74ad16fc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0a2607a0bbac48b09922e8847ebca61c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c92ed80c2a94434faddb653f2e319198":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f6ab60d5931f4e8cb4eb5df572496d5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b038c1eb1ea44de9433af9903bcb79e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_99155874e1c04d2a9c255723d5412c5c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b557bbd6d6f454786012cfdaf5724e0","IPY_MODEL_7dc286827d36435d952bacfce0178e3c"]}},"99155874e1c04d2a9c255723d5412c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b557bbd6d6f454786012cfdaf5724e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_56fdcfbe5ad64bbaa87080e5c6073749","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79a3dbd793b144a3b4d11735c1bfbd11"}},"7dc286827d36435d952bacfce0178e3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e9bc1a1e76ac4138bdcab54bb9b95ea2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 547kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84b50aa1dc6b468ab1355de1d88eef14"}},"56fdcfbe5ad64bbaa87080e5c6073749":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"79a3dbd793b144a3b4d11735c1bfbd11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9bc1a1e76ac4138bdcab54bb9b95ea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84b50aa1dc6b468ab1355de1d88eef14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74a52a1fee0343e6ab049367f405f70e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_afb43c4b0f7d46fb8dbad7c3a1c5c3a2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_323f5efcb07e410dbb23f8f0ccc345ef","IPY_MODEL_7c126ade93404d7da1342f276acb2406"]}},"afb43c4b0f7d46fb8dbad7c3a1c5c3a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"323f5efcb07e410dbb23f8f0ccc345ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a08a051ce7e64c69807064af41066685","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_741579e145964ab99e9f213836886f7a"}},"7c126ade93404d7da1342f276acb2406":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a262f59c8b440ad883bb6403efb9077","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 181B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc22b5b1dfd244a19cc6f0718752e577"}},"a08a051ce7e64c69807064af41066685":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"741579e145964ab99e9f213836886f7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a262f59c8b440ad883bb6403efb9077":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc22b5b1dfd244a19cc6f0718752e577":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcf435c59c204be8befceb5f4206df1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_796de3029da04d568c655f1766f4ffb1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_58dfdb87e59549d88f075930c3d6fd72","IPY_MODEL_85f954827c66440e8eba8c909965cb34"]}},"796de3029da04d568c655f1766f4ffb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58dfdb87e59549d88f075930c3d6fd72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_48dd4dd44393420fb0c9d957c39a0eaf","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10e6f00ff42646f287575fb7e2c4dda0"}},"85f954827c66440e8eba8c909965cb34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_675c2326bc7d4d8ea3803bb44a7f21ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 3.96MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6ec0d4b1c154d12918b54199046ab06"}},"48dd4dd44393420fb0c9d957c39a0eaf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"10e6f00ff42646f287575fb7e2c4dda0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"675c2326bc7d4d8ea3803bb44a7f21ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b6ec0d4b1c154d12918b54199046ab06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de51191eadb24c96ba1e842d33a6f67b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_271200e927214bff91d02e9f175bd6d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_84cd81f999834f54b03c80d95e88d366","IPY_MODEL_90a728d017d34c0db5a7e850fff28553"]}},"271200e927214bff91d02e9f175bd6d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84cd81f999834f54b03c80d95e88d366":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_22e88b9b81cf43439b1de34e69e2c161","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f771f5266b1547f4880afad5f22bd7a6"}},"90a728d017d34c0db5a7e850fff28553":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d1af524939b4106917fe9eff217e7c8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:24&lt;00:00, 17.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38191533025d49b39212db0c29806d9d"}},"22e88b9b81cf43439b1de34e69e2c161":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f771f5266b1547f4880afad5f22bd7a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d1af524939b4106917fe9eff217e7c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38191533025d49b39212db0c29806d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"AUc0ftVAUFZa"},"source":["# Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJbYXou6chZf","executionInfo":{"status":"ok","timestamp":1617438691201,"user_tz":-330,"elapsed":1189,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"3b763880-d22a-49e6-b6bf-c472ef437239"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Apr  3 08:31:30 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o9y3FtJV1kFx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617438692229,"user_tz":-330,"elapsed":2208,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"deab343e-c396-4244-f6e9-65f3bc6d68c2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount = True)\n","import os\n","root_path = 'gdrive/My Drive/HateXplain/'\n","os.chdir(root_path)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wt13ocCw50i9","executionInfo":{"status":"ok","timestamp":1617438692231,"user_tz":-330,"elapsed":2205,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["# !pip install sentencepiece==0.1.94\n","# !pip install transformers\n","# !pip install ekphrasis\n","# !pip install datasets"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"SY2T4gxT55uX","executionInfo":{"status":"ok","timestamp":1617438700616,"user_tz":-330,"elapsed":10584,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["import numpy as np\n","from datasets import list_datasets, load_dataset\n","import pandas as pd\n","import pickle\n","from transformers import AutoModel, AutoTokenizer\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","from torch.autograd import Function\n","import copy\n","from transformers import BertModel, RobertaModel, BertTokenizer, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\n","import sklearn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random\n","import pickle\n","import json\n","from sklearn.metrics import accuracy_score\n","from ekphrasis.classes.preprocessor import TextPreProcessor\n","from ekphrasis.classes.tokenizer import SocialTokenizer\n","from ekphrasis.dicts.emoticons import emoticons\n","import re\n","plt.rcParams['figure.figsize'] = [15, 8]\n","plt.rcParams.update({'font.size': 8})\n","RANDOM_SEED = 42\n","model_path = 'bert-base-uncased'\n","# model_path = 'monsoon-nlp/tamillion'\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ndv5efWr6WtI","executionInfo":{"status":"ok","timestamp":1617438700621,"user_tz":-330,"elapsed":10583,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value)  \n","    torch.manual_seed(seed_value)  \n","    random.seed(seed_value)\n","    if use_cuda:\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)  \n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","random_seed(RANDOM_SEED, True)\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8wci3NG6bmM","executionInfo":{"status":"ok","timestamp":1617438722029,"user_tz":-330,"elapsed":31987,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"1d54f608-ff63-4378-e90a-735ff29211df"},"source":["text_processor = TextPreProcessor(\n","    # terms that will be normalized\n","    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n","        'time', 'date', 'number'],\n","    # terms that will be annotated\n","    fix_html=True,  # fix HTML tokens\n","    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n","        'emphasis', 'censored'},\n","    # corpus from which the word statistics are going to be used \n","    # for word segmentation \n","    segmenter=\"twitter\", \n","    \n","    # corpus from which the word statistics are going to be used \n","    # for spell correction\n","    #corrector=\"twitter\", \n","    \n","    unpack_hashtags=True,  # perform word segmentation on hashtags\n","    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n","    spell_correct_elong=False,  # spell correction for elongated words\n","    \n","    # select a tokenizer. You can use SocialTokenizer, or pass your own\n","    # the tokenizer, should take as input a string and return a list of tokens\n","    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n","    \n","    # list of dictionaries, for replacing tokens extracted from the text,\n","    # with other expressions. You can pass more than one dictionaries.\n","    dicts=[emoticons]\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n","  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"],"name":"stderr"},{"output_type":"stream","text":["Word statistics files not found!\n","Downloading... done!\n","Unpacking... done!\n","Reading twitter - 1grams ...\n","generating cache file for faster loading...\n","reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n","Reading twitter - 2grams ...\n","generating cache file for faster loading...\n","reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n","  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"],"name":"stderr"},{"output_type":"stream","text":["Reading english - 1grams ...\n","generating cache file for faster loading...\n","reading ngrams /root/.ekphrasis/stats/english/counts_1grams.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FueChKcm6ej4","executionInfo":{"status":"ok","timestamp":1617438722029,"user_tz":-330,"elapsed":31984,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n","                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n","                                         random_state=None):\n","    if frac_train + frac_val + frac_test != 1.0:\n","        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n","                         (frac_train, frac_val, frac_test))\n","\n","    if stratify_colname not in df_input.columns:\n","        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n","\n","    X = df_input # Contains all columns.\n","    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n","\n","    # Split original dataframe into train and temp dataframes.\n","    df_train, df_temp, y_train, y_temp = train_test_split(X,\n","                                                          y,\n","                                                          stratify=y,\n","                                                          test_size=(1.0 - frac_train),\n","                                                          random_state=random_state)\n","\n","    # Split the temp dataframe into val and test dataframes.\n","    relative_frac_test = frac_test / (frac_val + frac_test)\n","    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n","                                                      y_temp,\n","                                                      stratify=y_temp,\n","                                                      test_size=relative_frac_test,\n","                                                      random_state=random_state)\n","\n","    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n","\n","    return df_train, df_val, df_test"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273,"referenced_widgets":["a0afce0b0c8b454a8a3b9c01a74f644f","30e269680eaa463f90649ce94cfbb6f3","223267c9995241e9aaef9f317a6fa043","665e0db88099495c959ce32e91280c95","9d0b233ebc6a40f992beb95692fd0112","180ed9c342c24e768001fa3603001855","2383f3c5f7be40dcb7790f5b20cc9183","d1c484f8cc9e42768fced4bfdd3c4aa8","a840cead5109421a8c902950af588345","596bee1cd68a4a3dab2bbaceefaf589f","5d503ce4862c4ba3aebe93c697c0452f","ffc06a0a6afb416b814587239cc49174","1f3a417cee7142c0ad0c1882168af883","d00089977ffe48ac9732ee683fa031b5","ef4517977365478381ae999357bf4fbf","a8987eff745b447d9fd8aa4c81426a4e","6e577de800c54f2b9181810eade80a0d","63cf875e29f9434b80a9c4290ceae42c","b4e04f5edef2459aad41f95ef1046159","b5b603651c92420484f108fd2e2d8753","1324b22c46e3422486d7707f9d6f9ea6","a967fa4807e94be0bd61a3796bb3c821","5cd2d857ec494397aae2494bdb8d444e","26d6f1f2931a4e24837ecf005fd29399","ee70602f67cb4cb0b602827e97a120b3","44e4370189ca4bc9ae9d457f2b646f97","b2b15a62e5c04c438572614749fc33b5","957c89ea613f4c20ab99cfe41da0806a","a8416b767b834698a0ef17de794bb06c","697563f9972d4bdf853298f0b6e23617","a2cb8710d3554023b28ac2f8c04cc3c3","482b8aa0249146dca1046ea80107f726","d03d0a9f9d2e4c0fb20aba0a22c077ba","bc3f51b0b9dd4972887aa6e8fe69eb07","b4511f31581d45e287ce626b151eabf0","7f582d91a3d64cdd86b69ddff3e86028","4809a43104af458ea27eff813ea2d718","374a7fe7624a4908b683bf8075c84ba9","3e21817befed48caa3dc18080c50f136","f3992ba274eb47e5bb5450909c0b88ef","7848a813969248cfb8faea96eac25c27","d919f00c597e4075b11dbc995c47dcee","fbafc9f6b3304ab28ad9b42cb024195e","34f82d4727874c758954db198edb4314","b6568ee85ca445f18f8a9d338ddc11cc","38505dc1dfdc40bd87b54e3354c5d88c","892b236d394e4e948e793fd09bffe78f","b6e13d6a5038431fab29f34c46c982f3","b0946beb202c4bbdbbbbb4b056ca437e","f47bba9738054ba0b7c1f796e37a3aec","9a7bdc6b01c94ff1adf4e8e581daaaf9","a7ff35a74e45420e8e75dbc6a53ef289","4a6e4484deb445789673b12fae1593c6","9dc23a51d0a245f795c1d6bfa6c6138a","c0a24d5dcb724293b17aa0d4d9f3aa94","6f23ad992e694878a016c64c4bc26f86"]},"id":"vcBTOQejC_zI","executionInfo":{"status":"ok","timestamp":1617438731684,"user_tz":-330,"elapsed":41636,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"1a4ed6e6-20d3-4adc-ea75-7b38fab5d532"},"source":["dataset = load_dataset('hatexplain', split = ['train', 'validation', 'test'])\n","\n","train_dataset = dataset[0]\n","valid_dataset = dataset[1]\n","test_dataset = dataset[2]"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0afce0b0c8b454a8a3b9c01a74f644f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1857.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a840cead5109421a8c902950af588345","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1131.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Downloading and preparing dataset hatexplain/plain_text (download: 12.25 MiB, generated: 8.47 MiB, post-processed: Unknown size, total: 20.73 MiB) to /root/.cache/huggingface/datasets/hatexplain/plain_text/1.0.0/802fcd855438812094e336cea509c99b04b890e4e0846c0385877ee2c7361e93...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e577de800c54f2b9181810eade80a0d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2028297.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee70602f67cb4cb0b602827e97a120b3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=145439.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d03d0a9f9d2e4c0fb20aba0a22c077ba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7848a813969248cfb8faea96eac25c27","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0946beb202c4bbdbbbbb4b056ca437e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rDataset hatexplain downloaded and prepared to /root/.cache/huggingface/datasets/hatexplain/plain_text/1.0.0/802fcd855438812094e336cea509c99b04b890e4e0846c0385877ee2c7361e93. Subsequent calls will reuse this data.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-VTWqLY0FBzY","colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["8315d9d057d0457094670cb410bd13c1","997fadf0f1c14e909e0c3013ab966c58","74d384be1f594cc999e207d368459e23","f0f715aa6a3e4baa98c402c9a6b52d54","b88d19f438d946ebb5ea0bf74ad16fc7","0a2607a0bbac48b09922e8847ebca61c","c92ed80c2a94434faddb653f2e319198","f6ab60d5931f4e8cb4eb5df572496d5e","7b038c1eb1ea44de9433af9903bcb79e","99155874e1c04d2a9c255723d5412c5c","9b557bbd6d6f454786012cfdaf5724e0","7dc286827d36435d952bacfce0178e3c","56fdcfbe5ad64bbaa87080e5c6073749","79a3dbd793b144a3b4d11735c1bfbd11","e9bc1a1e76ac4138bdcab54bb9b95ea2","84b50aa1dc6b468ab1355de1d88eef14","74a52a1fee0343e6ab049367f405f70e","afb43c4b0f7d46fb8dbad7c3a1c5c3a2","323f5efcb07e410dbb23f8f0ccc345ef","7c126ade93404d7da1342f276acb2406","a08a051ce7e64c69807064af41066685","741579e145964ab99e9f213836886f7a","3a262f59c8b440ad883bb6403efb9077","bc22b5b1dfd244a19cc6f0718752e577","bcf435c59c204be8befceb5f4206df1c","796de3029da04d568c655f1766f4ffb1","58dfdb87e59549d88f075930c3d6fd72","85f954827c66440e8eba8c909965cb34","48dd4dd44393420fb0c9d957c39a0eaf","10e6f00ff42646f287575fb7e2c4dda0","675c2326bc7d4d8ea3803bb44a7f21ba","b6ec0d4b1c154d12918b54199046ab06"]},"executionInfo":{"status":"ok","timestamp":1617438732990,"user_tz":-330,"elapsed":42939,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"61808598-8af6-41a2-bdb7-26adedf91855"},"source":["tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8315d9d057d0457094670cb410bd13c1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b038c1eb1ea44de9433af9903bcb79e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74a52a1fee0343e6ab049367f405f70e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcf435c59c204be8befceb5f4206df1c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PgYFB-R3F_TH","executionInfo":{"status":"ok","timestamp":1617438732992,"user_tz":-330,"elapsed":42938,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["import numpy as np\n","from numpy import array, exp\n","###this file contain different attention mask calculation from the n masks from n annotators. In this code there are 3 annotators\n","\n","##### We mostly use softmax\n","def softmax(x):\n","    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n","    e_x = np.exp(x - np.max(x))\n","    return e_x / e_x.sum(axis=0)\n"," \n","def neg_softmax(x):\n","    \"\"\"Compute softmax values for each sets of scores in x. Here we convert the exponentials to 1/exponentials\"\"\"\n","    e_x = np.exp(-(x - np.max(x)))\n","    return e_x / e_x.sum(axis=0)\n","def sigmoid(z):\n","      \"\"\"Compute sigmoid values\"\"\"\n","      g = 1 / (1 + exp(-z))\n","      return g\n","\n","##### This function is used to aggregate the attentions vectors. This has a lot of options refer to the parameters explanation for understanding each parameter.\n","def aggregate_attention(at_mask,row):\n","    \"\"\"input: attention vectors from 2/3 annotators (at_mask), row(dataframe row), params(parameters_dict)\n","       function: aggregate attention from different annotators.\n","       output: aggregated attention vector\"\"\"\n","    \n","    \n","    #### If the final label is normal or non-toxic then each value is represented by 1/len(sentences)\n","    if(row['final_label'] in ['normal','non-toxic']):\n","        at_mask_fin=[1/len(at_mask[0]) for x in at_mask[0]]\n","    else:\n","        at_mask_fin=at_mask\n","        #### Else it will choose one of the options, where variance is added, mean is calculated, finally the vector is normalised.   \n","        at_mask_fin=int(5)*at_mask_fin\n","        at_mask_fin=np.mean(at_mask_fin,axis=0)\n","        at_mask_fin=softmax(at_mask_fin)\n","\n","    return at_mask_fin"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSDaXjlxzpW1","executionInfo":{"status":"ok","timestamp":1617438732993,"user_tz":-330,"elapsed":42936,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def custom_tokenize(sent,tokenizer,max_length=512):\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    try:\n","\n","        encoded_sent = tokenizer.encode(\n","                            sent,                      # Sentence to encode.\n","                            add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n","                            #max_length = max_length,\n","                            # This function also supports truncation and conversion\n","                            # to pytorch tensors, but we need to do padding, so we\n","                            # can't use these features :( .\n","                            #max_length = 128,          # Truncate all sentences.\n","                            #return_tensors = 'pt',     # Return pytorch tensors.\n","                       )\n","\n","        # Add the encoded sentence to the list.\n","\n","    except ValueError:\n","        encoded_sent = tokenizer.encode(\n","                            ' ',                      # Sentence to encode.\n","                            add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n","                            max_length = max_length,\n","                    \n","                       )\n","          ### decide what to later\n","\n","    return encoded_sent\n","\n","def ek_extra_preprocess(text,tokenizer):\n","    remove_words=['<allcaps>','</allcaps>','<hashtag>','</hashtag>','<elongated>','<emphasis>','<repeated>','\\'','s']\n","    word_list=text_processor.pre_process_doc(text)\n","    # if(params['include_special']):\n","    #     pass\n","    # else:\n","    word_list=list(filter(lambda a: a not in remove_words, word_list)) \n","    # if(params['bert_tokens']):\n","    sent=\" \".join(word_list)\n","    sent = re.sub(r\"[<\\*>]\", \" \",sent)\n","    sub_word_list = custom_tokenize(sent,tokenizer)\n","    return sub_word_list"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"TT0zHt3nyW26","executionInfo":{"status":"ok","timestamp":1617438732994,"user_tz":-330,"elapsed":42933,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def returnMask(row,tokenizer):\n","    \n","    text_tokens=row['post_tokens']\n","    \n","    \n","    \n","    ##### a very rare corner case\n","    if(len(text_tokens)==0):\n","        text_tokens=['dummy']\n","        print(\"length of text ==0\")\n","    #####\n","    \n","    \n","    mask_all= row['rationales']\n","    mask_all_temp=mask_all\n","    count_temp=0\n","    while(len(mask_all_temp)!=3):\n","        mask_all_temp.append([0]*len(text_tokens))\n","    \n","    word_mask_all=[]\n","    word_tokens_all=[]\n","    \n","    for mask in mask_all_temp:\n","        if(mask[0]==-1):\n","            mask=[0]*len(mask)\n","        \n","        \n","        list_pos=[]\n","        mask_pos=[]\n","        \n","        flag=0\n","        for i in range(0,len(mask)):\n","            if(i==0 and mask[i]==0):\n","                list_pos.append(0)\n","                mask_pos.append(0)\n","            \n","            \n","            \n","            \n","            if(flag==0 and mask[i]==1):\n","                mask_pos.append(1)\n","                list_pos.append(i)\n","                flag=1\n","                \n","            elif(flag==1 and mask[i]==0):\n","                flag=0\n","                mask_pos.append(0)\n","                list_pos.append(i)\n","        if(list_pos[-1]!=len(mask)):\n","            list_pos.append(len(mask))\n","            mask_pos.append(0)\n","        string_parts=[]\n","        for i in range(len(list_pos)-1):\n","            string_parts.append(text_tokens[list_pos[i]:list_pos[i+1]])\n","        \n","        \n","        word_tokens=[101]\n","        word_mask=[0]\n","\n","        \n","        for i in range(0,len(string_parts)):\n","            tokens=ek_extra_preprocess(\" \".join(string_parts[i]),tokenizer)\n","            masks=[mask_pos[i]]*len(tokens)\n","            word_tokens+=tokens\n","            word_mask+=masks\n","\n","\n","        # if(params['bert_tokens']):\n","        ### always post truncation\n","        word_tokens=word_tokens[0:(int(128)-2)]\n","        word_mask=word_mask[0:(int(128)-2)]\n","        word_tokens.append(102)\n","        word_mask.append(0)\n","\n","        word_mask_all.append(word_mask)\n","        word_tokens_all.append(word_tokens)\n","        \n","#     for k in range(0,len(mask_all)):\n","#          if(mask_all[k][0]==-1):\n","#             word_mask_all[k] = [-1]*len(word_mask_all[k])\n","    if(len(mask_all)==0):\n","        word_mask_all=[]\n","    else:    \n","        word_mask_all=word_mask_all[0:len(mask_all)]\n","    return word_tokens_all[0],word_mask_all"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXxR14lf76Ae","executionInfo":{"status":"ok","timestamp":1617438732995,"user_tz":-330,"elapsed":42931,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["dict_label = {0: 'hatespeech', 1: 'normal', 2:'offensive'}"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"1f1CWkNR8xOf","executionInfo":{"status":"ok","timestamp":1617438732996,"user_tz":-330,"elapsed":42929,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["class Dataset():\n","    def __init__(self, data, batch_size = 16, train = False):\n","        self.data = data\n","        # self.val_data = val_data\n","        self.batch_size = batch_size\n","        self.train = train\n","        # self.label_dict = {0: 0,\n","        #                     1: 2,\n","        #                     2: 1}\n","                                    \n","        self.count_dic = {}\n","        self.inputs, self.labels, self.attn = self.process_data(self.data)\n","        self.DataLoader = self.get_dataloader(self.inputs, self.attn, self.labels)\n","        # self.train_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'train')\n","        # self.val_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n","        # self.test_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n","\n","    def tokenize(self, sentences, padding = True, max_len = 128):\n","        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n","        input_ids, attention_masks, token_type_ids = [], [], []\n","        for sent in sentences:\n","            encoded_dict = tokenizer.encode_plus(sent,\n","                                                    add_special_tokens=True,\n","                                                    max_length=max_len, \n","                                                    padding='max_length', \n","                                                    return_attention_mask = True,\n","                                                    return_tensors = 'pt', \n","                                                    truncation = True)\n","            input_ids.append(encoded_dict['input_ids'])\n","            attention_masks.append(encoded_dict['attention_mask'])\n","        \n","        input_ids = torch.cat(input_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","\n","        return {'input_ids': input_ids, 'attention_masks': attention_masks}\n","    \n","    def process_data(self, data):\n","        sentences, labels, attn = [], [], []\n","        print(len(data))\n","        for row in data:\n","            word_tokens_all, word_mask_all = returnMask(row, tokenizer)\n","            label = max(set(row['annotators']['label']), key = row['annotators']['label'].count)\n","            # label = self.label_dict[label]\n","            sentence = ' '.join(row['post_tokens'])\n","            sentences.append(sentence)\n","            labels.append(label)\n","            row['final_label'] = dict_label[label]\n","            at_mask = np.array(aggregate_attention(word_mask_all,row))\n","            at_mask = at_mask.tolist() + [0]*(128-len(at_mask))\n","\n","            attn.append(at_mask)\n","        inputs = self.tokenize(sentences)\n","        return inputs, torch.Tensor(labels), torch.Tensor(attn)\n","    \n","    def get_dataloader(self, inputs, attn, labels, train = True):\n","        data = TensorDataset(inputs['input_ids'], inputs['attention_masks'], attn, labels)\n","        if self.train:\n","            sampler = RandomSampler(data)\n","        else:\n","            sampler = SequentialSampler(data)\n","        return DataLoader(data, sampler=sampler, batch_size=self.batch_size, drop_last=True)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQZBoHVCQVGf","executionInfo":{"status":"ok","timestamp":1617438838865,"user_tz":-330,"elapsed":148795,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"977e340e-bfe7-4c44-9bce-b5b61134128c"},"source":["train_data_source = Dataset(train_dataset, train = True)\n","val_data_source = Dataset(valid_dataset)\n","test_data_source = Dataset(test_dataset)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["15383\n","1922\n","1924\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WpKsJP_nhUx","executionInfo":{"status":"ok","timestamp":1617451486219,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"63e469f0-5667-45cb-90e6-6b9d5189d7d1"},"source":["Counter(train_data_source.labels.tolist())Counter({0.0: 4748, 1.0: 6251, 2.0: 4384})"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({0.0: 4748, 1.0: 6251, 2.0: 4384})"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"kVgu41Kn6wtO","executionInfo":{"status":"ok","timestamp":1617438838865,"user_tz":-330,"elapsed":148792,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["class Dataset():\n","    def __init__(self, data, batch_size = 16, train = False, max_len = 128):\n","        self.data = data\n","        # self.val_data = val_data\n","        self.batch_size = batch_size\n","        self.train = train\n","        self.label_dict = {0: 0,\n","                            1: 2,\n","                            2: 1}\n","                                    \n","        self.count_dic = {}\n","        self.inputs, self.labels = self.process_data(self.data)\n","        self.DataLoader = self.get_dataloader(self.inputs, self.labels)\n","        # self.train_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'train')\n","        # self.val_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n","        # self.test_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n","\n","    def ek_extra_preprocess(self, text):\n","        remove_words=['<allcaps>','</allcaps>','<hashtag>','</hashtag>','<elongated>','<emphasis>','<repeated>','\\'','s']\n","        word_list=text_processor.pre_process_doc(text)\n","        word_list=list(filter(lambda a: a not in remove_words, word_list)) \n","        sent=\" \".join(word_list)\n","        sent = re.sub(r\"[<\\*>]\", \" \",sent)\n","        return sent\n","\n","    def tokenize(self, sentences, padding = True, max_len = 128):\n","        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n","        input_ids, attention_masks, token_type_ids = [], [], []\n","        for sent in sentences:\n","            encoded_dict = tokenizer.encode_plus(sent,\n","                                                    add_special_tokens=True,\n","                                                    max_length=max_len, \n","                                                    padding='max_length', \n","                                                    return_attention_mask = True,\n","                                                    return_tensors = 'pt', \n","                                                    truncation = True)\n","            input_ids.append(encoded_dict['input_ids'])\n","            attention_masks.append(encoded_dict['attention_mask'])\n","        \n","        input_ids = torch.cat(input_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","\n","        return {'input_ids': input_ids, 'attention_masks': attention_masks}\n","    \n","    def process_data(self, data):\n","        sentences, labels = [], []\n","        print(len(data))\n","        for label, sentence in zip(list(data['class']), list(data['tweet'])):\n","            label = self.label_dict[label]\n","            sentence = self.ek_extra_preprocess(sentence)\n","            sentences.append(sentence)\n","            labels.append(label)\n","        inputs = self.tokenize(sentences)\n","        return inputs, torch.Tensor(labels)\n","    \n","    def get_dataloader(self, inputs, labels, train = True):\n","        data = TensorDataset(inputs['input_ids'], inputs['attention_masks'], labels)\n","        if self.train:\n","            sampler = RandomSampler(data)\n","        else:\n","            sampler = SequentialSampler(data)\n","        return DataLoader(data, sampler=sampler, batch_size=self.batch_size, drop_last=True)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"2uz-Fwmd60gk","executionInfo":{"status":"ok","timestamp":1617438838866,"user_tz":-330,"elapsed":148790,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["# df = pd.read_csv('Data/labeled_data.csv', sep=',', engine='python')\n","# df = df.rename(columns={'Unnamed: 0': 'id'})\n","# df_train, df_val, df_test = split_stratified_into_train_val_test(df, stratify_colname='class',\n","#                                          frac_train=0.8, frac_val=0.1, frac_test=0.1,\n","#                                          random_state=RANDOM_SEED)\n","# df_train.to_csv('Data/train_data.csv',index = False)\n","# df_val.to_csv('Data/val_data.csv',index = False)\n","# df_test.to_csv('Data/test_data.csv',index = False)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7LupkwM6ygP","executionInfo":{"status":"ok","timestamp":1617451197920,"user_tz":-330,"elapsed":943,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["df_train = pd.read_csv('Data/train_data.csv', sep=',', engine='python')\n","df_val = pd.read_csv('Data/val_data.csv', sep=',', engine='python')\n","df_test = pd.read_csv('Data/test_data.csv', sep=',', engine='python')"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oa1-L0W8mqzX","executionInfo":{"status":"ok","timestamp":1617451321252,"user_tz":-330,"elapsed":1493,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"13cc3e74-e4f9-411d-9cb0-82334cb7af4f"},"source":["from collections import Counter\n","Counter(df_train['class'])"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({0: 1144, 1: 15352, 2: 3330})"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"rM1GfkXN-ckQ","executionInfo":{"status":"ok","timestamp":1617438840332,"user_tz":-330,"elapsed":150249,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["class GradReverse(Function):\n","    @staticmethod\n","    def forward(ctx, x, lambd):\n","        ctx.lambd = lambd\n","        return x.view_as(x)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        return (grad_output * -ctx.lambd), None\n","\n","\n","def grad_reverse(x, lambd=1.0):\n","    return GradReverse.apply(x, lambd)\n","\n","\n","def calc_coeff(iter_num, high=1.0, low=0.0, alpha=10.0, max_iter=10000.0):\n","    return np.float(2.0 * (high - low) /\n","                    (1.0 + np.exp(-alpha * iter_num / max_iter)) -\n","                    (high - low) + low)\n","\n","\n","def entropy(F1, feat, lamda, eta=1.0):\n","    out_t1 = F1(feat, reverse=True, eta=-eta)\n","    out_t1 = F.softmax(out_t1)\n","    loss_ent = -lamda * torch.mean(torch.sum(out_t1 *\n","                                             (torch.log(out_t1 + 1e-5)), 1))\n","    return loss_ent\n","\n","\n","def adentropy(F1, feat, lamda, eta=1.0):\n","    out_t1 = F1(feat, reverse=True, eta=eta)\n","    out_t1 = F.softmax(out_t1)\n","    loss_adent = lamda * torch.mean(torch.sum(out_t1 *\n","                                              (torch.log(out_t1 + 1e-5)), 1))\n","    return loss_adent\n","\n","class Predictor(nn.Module):\n","    def __init__(self, num_class=64, inc=4096, temp=0.05):\n","        super(Predictor, self).__init__()\n","        self.fc = nn.Linear(inc, num_class, bias=False)\n","        self.num_class = num_class\n","        self.temp = temp\n","\n","    def forward(self, x, reverse=False, eta=0.1):\n","        if reverse:\n","            x = grad_reverse(x, eta)\n","        x = F.normalize(x)\n","        x_out = self.fc(x) / self.temp\n","        return x_out"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"34kRQRsI65iK","executionInfo":{"status":"ok","timestamp":1617438840333,"user_tz":-330,"elapsed":150247,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def cross_entropy(input1, target, size_average=True):\n","    logsoftmax = nn.LogSoftmax(dim=0)\n","    return torch.sum(-target * logsoftmax(input1))\n","\n","def masked_cross_entropy(input1,target,mask):\n","    cr_ent=0\n","    for h in range(0,mask.shape[0]):\n","        cr_ent+=cross_entropy(input1[h][mask[h]],target[h][mask[h]])\n","    \n","    return cr_ent/mask.shape[0]\n","\n","class SC_weighted_BERT(nn.Module):\n","    def __init__(self, model_path):\n","        super(SC_weighted_BERT, self).__init__()\n","        self.num_labels = 3\n","        self.weights=[1.0795518,  0.82139814, 1.1678787]\n","        self.train_att= True\n","        self.lam = 100\n","        self.num_sv_heads = 6\n","        self.sv_layer = 11\n","        self.bert = AutoModel.from_pretrained(model_path, output_attentions = True)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(768, 3)\n","        #self.softmax=nn.Softmax(config.num_labels)\n","        # self.init_weights()\n","\n","    def forward(self, input_ids=None, attention_mask=None, attn = None, attn_lam = 0):\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","        )\n","\n","        pooled_output = outputs[1]\n","        if attn is None:\n","            return pooled_output\n","\n","        outputs = (pooled_output,) + outputs[2:]  # add hidden states and attention if they are here\n","        loss= 0\n","        if(self.train_att):\n","            loss_att=0\n","            for i in range(self.num_sv_heads):\n","                attention_weights=outputs[1][self.sv_layer][:,i,0,:]\n","                loss_att +=attn_lam*masked_cross_entropy(attention_weights,attn,attention_mask)\n","            loss = loss + loss_att\n","        outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), (pooled output), etc."],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYJBKhlWBJUv","executionInfo":{"status":"ok","timestamp":1617438840335,"user_tz":-330,"elapsed":150247,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def train():\n","    G.train()\n","    F1.train()\n","    optimizer_g = optim.SGD(params, momentum=0.9,\n","                            weight_decay=0.0005, nesterov=True)\n","    optimizer_f = optim.SGD(list(F1.parameters()), lr=1.0, momentum=0.9,\n","                            weight_decay=0.0005, nesterov=True)\n","\n","    def zero_grad_all():\n","        optimizer_g.zero_grad()\n","        optimizer_f.zero_grad()\n","    param_lr_g = []\n","    for param_group in optimizer_g.param_groups:\n","        param_lr_g.append(param_group[\"lr\"])\n","    param_lr_f = []\n","    for param_group in optimizer_f.param_groups:\n","        param_lr_f.append(param_group[\"lr\"])\n","    criterion = nn.CrossEntropyLoss().cuda()\n","    all_step = args.steps\n","    data_iter_s = iter(source_loader)\n","    data_iter_t = iter(target_loader)\n","    data_iter_t_unl = iter(target_loader_unl)\n","    len_train_source = len(source_loader)\n","    len_train_target = len(target_loader)\n","    len_train_target_semi = len(target_loader_unl)\n","    best_acc = 0\n","    counter = 0\n","    for step in range(all_step):\n","        optimizer_g = inv_lr_scheduler(param_lr_g, optimizer_g, step,\n","                                       init_lr=args.lr)\n","        optimizer_f = inv_lr_scheduler(param_lr_f, optimizer_f, step,\n","                                       init_lr=args.lr)\n","        lr = optimizer_f.param_groups[0]['lr']\n","        if step % len_train_target == 0:\n","            data_iter_t = iter(target_loader)\n","        if step % len_train_target_semi == 0:\n","            data_iter_t_unl = iter(target_loader_unl)\n","        if step % len_train_source == 0:\n","            data_iter_s = iter(source_loader)\n","        data_t = next(data_iter_t)\n","        data_t_unl = next(data_iter_t_unl)\n","        data_s = next(data_iter_s)\n","        im_data_s.data.resize_(data_s[0].size()).copy_(data_s[0])\n","        gt_labels_s.data.resize_(data_s[1].size()).copy_(data_s[1])\n","        im_data_t.data.resize_(data_t[0].size()).copy_(data_t[0])\n","        gt_labels_t.data.resize_(data_t[1].size()).copy_(data_t[1])\n","        im_data_tu.data.resize_(data_t_unl[0].size()).copy_(data_t_unl[0])\n","        zero_grad_all()\n","        data = torch.cat((im_data_s, im_data_t), 0)\n","        target = torch.cat((gt_labels_s, gt_labels_t), 0)\n","        output = G(data)\n","        out1 = F1(output)\n","        loss = criterion(out1, target)\n","        loss.backward(retain_graph=True)\n","        optimizer_g.step()\n","        optimizer_f.step()\n","        zero_grad_all()\n","        if not args.method == 'S+T':\n","            output = G(im_data_tu)\n","            if args.method == 'ENT':\n","                loss_t = entropy(F1, output, args.lamda)\n","                loss_t.backward()\n","                optimizer_f.step()\n","                optimizer_g.step()\n","            elif args.method == 'MME':\n","                loss_t = adentropy(F1, output, args.lamda)\n","                loss_t.backward()\n","                optimizer_f.step()\n","                optimizer_g.step()\n","            else:\n","                raise ValueError('Method cannot be recognized.')\n","            log_train = 'S {} T {} Train Ep: {} lr{} \\t ' \\\n","                        'Loss Classification: {:.6f} Loss T {:.6f} ' \\\n","                        'Method {}\\n'.format(args.source, args.target,\n","                                             step, lr, loss.data,\n","                                             -loss_t.data, args.method)\n","        else:\n","            log_train = 'S {} T {} Train Ep: {} lr{} \\t ' \\\n","                        'Loss Classification: {:.6f} Method {}\\n'.\\\n","                format(args.source, args.target,\n","                       step, lr, loss.data,\n","                       args.method)\n","        G.zero_grad()\n","        F1.zero_grad()\n","        zero_grad_all()\n","        if step % args.log_interval == 0:\n","            print(log_train)\n","        if step % args.save_interval == 0 and step > 0:\n","            loss_test, acc_test = test(target_loader_test)\n","            loss_val, acc_val = test(target_loader_val)\n","            G.train()\n","            F1.train()\n","            if acc_val >= best_acc:\n","                best_acc = acc_val\n","                best_acc_test = acc_test\n","                counter = 0\n","            else:\n","                counter += 1\n","            if args.early:\n","                if counter > args.patience:\n","                    break\n","            print('best acc test %f best acc val %f' % (best_acc_test,\n","                                                        acc_val))\n","            print('record %s' % record_file)\n","            with open(record_file, 'a') as f:\n","                f.write('step %d best %f final %f \\n' % (step,\n","                                                         best_acc_test,\n","                                                         acc_val))\n","            G.train()\n","            F1.train()\n","            if args.save_check:\n","                print('saving model')\n","                torch.save(G.state_dict(),\n","                           os.path.join(args.checkpath,\n","                                        \"G_iter_model_{}_{}_\"\n","                                        \"to_{}_step_{}.pth.tar\".\n","                                        format(args.method, args.source,\n","                                               args.target, step)))\n","                torch.save(F1.state_dict(),\n","                           os.path.join(args.checkpath,\n","                                        \"F1_iter_model_{}_{}_\"\n","                                        \"to_{}_step_{}.pth.tar\".\n","                                        format(args.method, args.source,\n","                                               args.target, step)))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYQwUXNh67IG","executionInfo":{"status":"ok","timestamp":1617438840957,"user_tz":-330,"elapsed":150866,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["import copy\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"," \n","def get_predicted(preds):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    return pred_flat\n"," \n","def evaluate(test_dataloader, feature_encoder, classifer):\n","    feature_encoder.eval()\n","    classifier.eval()\n","\n","    y_preds, y_test = np.array([]), np.array([])\n","\n","    for batch in test_dataloader:\n","        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device).long()\n","        with torch.no_grad():        \n","            ypred = feature_encoder(b_input_ids, b_input_mask)\n","            ypred = classifier(ypred)\n","\n","        ypred = ypred.cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        y_preds = np.hstack((y_preds, get_predicted(ypred)))\n","        y_test = np.hstack((y_test, label_ids))\n","\n","    weighted_f1 = f1_score(y_test, y_preds, average='macro')\n","    report = classification_report(y_test, y_preds)\n","    print(report)\n","    return weighted_f1, y_preds, y_test\n"," \n","def train(source_dataloader, target_labelled_dataloader, target_unlabelled_dataloader, validation_dataloader, \n","          feature_encoder, classifier, attn_lam = 0.01, learning_rate = 2e-5, steps = 1000):\n","    losses = []\n","    total_steps = steps\n","    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in feature_encoder.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in feature_encoder.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","\n","    optimizer_feature_encoder = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps = 1e-8)\n","    scheduler_feature_encoder = get_linear_schedule_with_warmup(optimizer_feature_encoder, \n","                                                num_warmup_steps = 0, # Default value in run_glue.py\n","                                                num_training_steps = total_steps)\n","    \n","    optimizer_classifier = AdamW(list(classifier.parameters()), lr=learning_rate*10, eps = 1e-8)\n","    scheduler_classifier = get_linear_schedule_with_warmup(optimizer_classifier, \n","                                                num_warmup_steps = 0, # Default value in run_glue.py\n","                                                num_training_steps = total_steps)\n","    \n","    \n","    best_weighted_f1 = 0\n","    best_feature_encoder, best_classifier = None, None\n","    # current_epoch, best_weighted_f1 = load_metrics(filepath, model, optimizer)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    len_source = len(source_dataloader)\n","    len_target_l = len(target_labelled_dataloader)\n","    len_target_ul = len(target_unlabelled_dataloader)\n","\n","    feature_encoder.train()\n","    classifier.train()\n","\n","    for step in range(total_steps):\n","        if step % len_source == 0:\n","            data_iter_s = iter(source_dataloader)\n","        if step % len_target_l == 0:\n","            data_iter_tl = iter(target_labelled_dataloader)\n","        if step % len_target_ul == 0:\n","            data_iter_tu = iter(target_unlabelled_dataloader)\n","\n","        batch_s = next(data_iter_s)\n","        batch_tl = next(data_iter_tl)\n","        batch_tu = next(data_iter_tu)\n","\n","        b_input_ids_s, b_input_mask_s, b_attn_s, b_labels_s = batch_s[0].to(device), batch_s[1].to(device), batch_s[2].to(device), batch_s[3].to(device).long()\n","        b_input_ids_tl, b_input_mask_tl, b_labels_tl = batch_tl[0].to(device), batch_tl[1].to(device), batch_tl[2].to(device).long()\n","        b_input_ids_tu, b_input_mask_tu, b_labels_tu = batch_tu[0].to(device), batch_tu[1].to(device), batch_tu[2].to(device).long()\n","        \n","        out1 = feature_encoder(b_input_ids_s, b_input_mask_s, attn = b_attn_s, attn_lam = attn_lam)\n","        logits1 = classifier(out1[1])\n","\n","        out2 = feature_encoder(b_input_ids_tl, b_input_mask_tl)\n","        logits2 = classifier(out2)\n","        \n","        loss_attn = out1[0]\n","\n","        loss = criterion(torch.cat([logits1, logits2], dim = 0), torch.cat([b_labels_s, b_labels_tl], dim = 0)) + loss_attn\n","\n","        output = feature_encoder(b_input_ids_tu, b_input_mask_tu)\n","        loss_t = adentropy(classifier, output, 0.1)\n","        loss += loss_t\n","        \n","        if step%50 == 0:\n","            print(loss.item())\n","            losses.append(float(loss))\n","            print('### Validation Set Stats')\n","            weighted_f1, ypred, ytest = evaluate(validation_dataloader, feature_encoder, classifier)\n","            print(\"  Macro F1: {0:.3f}\".format(weighted_f1))\n","            if weighted_f1 > best_weighted_f1:\n","                best_weighted_f1 = weighted_f1\n","                best_feature_encoder = copy.deepcopy(feature_encoder)\n","                best_classifier = copy.deepcopy(classifier)\n","                # save_metrics(filepath, epoch_i, model, optimizer, weighted_f1)\n","\n","        optimizer_feature_encoder.zero_grad()\n","        optimizer_classifier.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(feature_encoder.parameters(), 1.0)\n","        optimizer_feature_encoder.step()\n","        optimizer_classifier.step()\n","\n","        scheduler_feature_encoder.step()\n","        scheduler_classifier.step() \n","        \n","    return best_feature_encoder, best_classifier, losses"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IiCDFwVBXfp","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["de51191eadb24c96ba1e842d33a6f67b","271200e927214bff91d02e9f175bd6d0","84cd81f999834f54b03c80d95e88d366","90a728d017d34c0db5a7e850fff28553","22e88b9b81cf43439b1de34e69e2c161","f771f5266b1547f4880afad5f22bd7a6","6d1af524939b4106917fe9eff217e7c8","38191533025d49b39212db0c29806d9d"]},"executionInfo":{"status":"ok","timestamp":1617438865686,"user_tz":-330,"elapsed":175591,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"170c2edf-4187-48b3-e165-a0fe67272b7a"},"source":["feature_encoder = SC_weighted_BERT(model_path).to(device)\n","classifier = Predictor(num_class=3, inc = 768).to(device)\n","# model.load_state_dict(torch.load('./Saved/bert-base-uncased_11_6_3_100/pytorch_model.bin', 'cpu'))"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de51191eadb24c96ba1e842d33a6f67b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UsVdB3sva0MK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617438891806,"user_tz":-330,"elapsed":201708,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"7bd2612b-7a8d-4e23-9dc8-9e21acc8b45a"},"source":["n = 50\n","train_data_target_unlabelled = Dataset(df_train, train = True)\n","val_data, test_data = Dataset(df_val), Dataset(df_test)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["19826\n","2478\n","2479\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BHx6SEgY8tEC","executionInfo":{"status":"ok","timestamp":1617438891807,"user_tz":-330,"elapsed":201705,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["# feature_encoder, classifier, losses = train(train_data_source.DataLoader, train_data_target_labelled.DataLoader,\n","#       train_data_target_unlabelled.DataLoader, val_data.DataLoader, \n","#       feature_encoder, classifier, attn_lam = 0.01, learning_rate = 2e-5, steps = 5000)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNtFwBSIyxBv","executionInfo":{"status":"ok","timestamp":1617438891807,"user_tz":-330,"elapsed":201702,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["try:\n","    with open('SSDA/results_davidson.pkl', 'rb') as f:\n","        data_dict = pickle.load(f)\n","except:\n","    data_dict = {}\n","    with open('SSDA/results_davidson.pkl', 'wb') as f:\n","        pickle.dump(data_dict, f)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-3TbtNUwEbT","executionInfo":{"status":"ok","timestamp":1617451152967,"user_tz":-330,"elapsed":12462860,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"368756ad-6eab-4396-b162-7873e7226ba0"},"source":["attentions = [0, 0.001, 0.01, 0.1, 1, 10, 100]\n","N = [20, 50, 100, 200, 300, 400, 500, 1000]\n","for n in N:\n","    if n!=0:\n","        df = pd.concat([df_train[df_train['class']==0].sample(n=n, random_state = RANDOM_SEED),\n","                    df_train[df_train['class']==1].sample(n=n, random_state = RANDOM_SEED),\n","                    df_train[df_train['class']==2].sample(n=n, random_state = RANDOM_SEED)],\n","                    ignore_index = True)\n","        train_data_target_labelled = Dataset(df, batch_size = 16, train = True)\n","\n","    for attn in attentions:\n","        if attn not in data_dict: data_dict[attn] = {}\n","        if n in data_dict[attn]: continue\n","        feature_encoder = SC_weighted_BERT(model_path).to(device)\n","        classifier = Predictor(num_class=3, inc = 768).to(device)\n","        if n!=0:\n","            feature_encoder, classifier, losses = train(train_data_source.DataLoader, train_data_target_labelled.DataLoader,\n","            train_data_target_unlabelled.DataLoader, val_data.DataLoader, \n","            feature_encoder, classifier, attn_lam = 0.01, learning_rate = 2e-5, steps = 1000)\n","\n","        f1, ypreds, ytest = evaluate(test_data.DataLoader, feature_encoder, classifier)\n","        acc = accuracy_score(ytest, ypreds)\n","        with open('SSDA/results_davidson.pkl', 'rb') as f:\n","            data_dict = pickle.load(f)\n","        if attn not in data_dict: data_dict[attn] = {}\n","        data_dict[attn][n] = {'f1': f1, 'acc':acc}\n","        print(attn, n, data_dict[attn][n])\n","        with open('SSDA/results_davidson.pkl', 'wb') as f:\n","            pickle.dump(data_dict, f)\n","        print(data_dict)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["60\n","150\n","300\n","600\n","900\n","1200\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["2.7982540130615234\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00       143\n","         1.0       0.17      0.01      0.01       414\n","         2.0       0.77      0.99      0.87      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.31      0.33      0.29      2464\n","weighted avg       0.63      0.77      0.67      2464\n","\n","  Macro F1: 0.294\n","2.4281558990478516\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.59      0.31       143\n","         1.0       0.58      0.67      0.62       414\n","         2.0       0.91      0.76      0.83      1907\n","\n","    accuracy                           0.73      2464\n","   macro avg       0.57      0.67      0.59      2464\n","weighted avg       0.82      0.73      0.76      2464\n","\n","  Macro F1: 0.587\n","2.390320062637329\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.64      0.36       143\n","         1.0       0.89      0.53      0.67       414\n","         2.0       0.91      0.88      0.89      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.68      0.68      0.64      2464\n","weighted avg       0.87      0.81      0.82      2464\n","\n","  Macro F1: 0.639\n","2.0464229583740234\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.70      0.39       143\n","         1.0       0.72      0.92      0.80       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.65      0.80      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.689\n","2.6117630004882812\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.66      0.35       143\n","         1.0       0.76      0.83      0.79       414\n","         2.0       0.96      0.81      0.88      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.65      0.77      0.67      2464\n","weighted avg       0.88      0.80      0.83      2464\n","\n","  Macro F1: 0.673\n","1.713299036026001\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.76      0.33       143\n","         1.0       0.75      0.87      0.80       414\n","         2.0       0.97      0.75      0.85      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.64      0.79      0.66      2464\n","weighted avg       0.89      0.77      0.81      2464\n","\n","  Macro F1: 0.661\n","2.1122384071350098\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.72      0.34       143\n","         1.0       0.69      0.89      0.78       414\n","         2.0       0.97      0.74      0.84      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.63      0.78      0.65      2464\n","weighted avg       0.88      0.77      0.80      2464\n","\n","  Macro F1: 0.651\n","2.055462598800659\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.70      0.35       143\n","         1.0       0.79      0.85      0.82       414\n","         2.0       0.96      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.79      0.68      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.682\n","1.736023187637329\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.77      0.32       143\n","         1.0       0.84      0.80      0.82       414\n","         2.0       0.96      0.77      0.86      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.67      0.78      0.67      2464\n","weighted avg       0.90      0.78      0.82      2464\n","\n","  Macro F1: 0.667\n","2.040709972381592\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.74      0.35       143\n","         1.0       0.79      0.83      0.81       414\n","         2.0       0.96      0.79      0.87      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.66      0.79      0.67      2464\n","weighted avg       0.89      0.79      0.83      2464\n","\n","  Macro F1: 0.673\n","2.211907386779785\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.78      0.32       143\n","         1.0       0.78      0.86      0.82       414\n","         2.0       0.97      0.74      0.84      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.65      0.80      0.66      2464\n","weighted avg       0.90      0.77      0.81      2464\n","\n","  Macro F1: 0.661\n","2.0166618824005127\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.58      0.42       143\n","         1.0       0.72      0.89      0.80       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.77      0.70      2464\n","weighted avg       0.88      0.84      0.86      2464\n","\n","  Macro F1: 0.705\n","2.335705041885376\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.71      0.38       143\n","         1.0       0.73      0.88      0.80       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.80      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.688\n","1.5358691215515137\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.67      0.37       143\n","         1.0       0.79      0.85      0.82       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.78      0.69      2464\n","weighted avg       0.89      0.82      0.85      2464\n","\n","  Macro F1: 0.690\n","2.147902488708496\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.66      0.39       143\n","         1.0       0.77      0.87      0.82       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.79      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.699\n","2.2089908123016357\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.59      0.38       143\n","         1.0       0.73      0.91      0.81       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.78      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.691\n","1.9742398262023926\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.68      0.38       143\n","         1.0       0.73      0.91      0.81       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.65      0.80      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.688\n","2.048417806625366\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.62      0.42       143\n","         1.0       0.74      0.92      0.82       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.79      0.71      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.710\n","2.024195909500122\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.64      0.40       143\n","         1.0       0.73      0.90      0.81       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.79      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.701\n","2.3829915523529053\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.64      0.40       143\n","         1.0       0.76      0.90      0.82       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.79      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.703\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.57      0.40       142\n","         1.0       0.74      0.89      0.81       413\n","         2.0       0.96      0.85      0.90      1909\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.77      0.70      2464\n","weighted avg       0.88      0.84      0.86      2464\n","\n","100 400 {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}}}\n","1500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["3.0729732513427734\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00       143\n","         1.0       0.09      0.02      0.03       414\n","         2.0       0.77      0.96      0.85      1907\n","\n","    accuracy                           0.74      2464\n","   macro avg       0.29      0.33      0.30      2464\n","weighted avg       0.61      0.74      0.67      2464\n","\n","  Macro F1: 0.295\n","2.5160515308380127\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.48      0.30       143\n","         1.0       0.49      0.75      0.59       414\n","         2.0       0.91      0.72      0.80      1907\n","\n","    accuracy                           0.71      2464\n","   macro avg       0.54      0.65      0.56      2464\n","weighted avg       0.80      0.71      0.74      2464\n","\n","  Macro F1: 0.564\n","1.8197236061096191\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.75      0.32       143\n","         1.0       0.77      0.77      0.77       414\n","         2.0       0.96      0.77      0.85      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.65      0.76      0.65      2464\n","weighted avg       0.88      0.77      0.81      2464\n","\n","  Macro F1: 0.649\n","2.1826720237731934\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.76      0.35       143\n","         1.0       0.73      0.85      0.79       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.64      0.79      0.67      2464\n","weighted avg       0.89      0.78      0.82      2464\n","\n","  Macro F1: 0.666\n","2.352850914001465\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.78      0.31       143\n","         1.0       0.75      0.86      0.80       414\n","         2.0       0.97      0.72      0.83      1907\n","\n","    accuracy                           0.75      2464\n","   macro avg       0.64      0.79      0.65      2464\n","weighted avg       0.89      0.75      0.79      2464\n","\n","  Macro F1: 0.647\n","2.194420576095581\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.74      0.42       143\n","         1.0       0.75      0.88      0.81       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.707\n","2.116835594177246\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.72      0.38       143\n","         1.0       0.78      0.86      0.82       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.80      0.69      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.693\n","2.0974366664886475\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.73      0.37       143\n","         1.0       0.71      0.89      0.79       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.64      0.80      0.67      2464\n","weighted avg       0.89      0.79      0.82      2464\n","\n","  Macro F1: 0.672\n","2.290360689163208\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.38      0.64      0.47       143\n","         1.0       0.75      0.90      0.82       414\n","         2.0       0.96      0.87      0.91      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.70      0.80      0.74      2464\n","weighted avg       0.89      0.86      0.87      2464\n","\n","  Macro F1: 0.735\n","2.245065927505493\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.75      0.32       143\n","         1.0       0.81      0.82      0.81       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.66      0.78      0.67      2464\n","weighted avg       0.90      0.78      0.82      2464\n","\n","  Macro F1: 0.665\n","2.100334882736206\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.62      0.41       143\n","         1.0       0.70      0.91      0.79       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.79      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.699\n","1.9828717708587646\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.71      0.34       143\n","         1.0       0.76      0.85      0.81       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.65      0.78      0.67      2464\n","weighted avg       0.89      0.79      0.82      2464\n","\n","  Macro F1: 0.669\n","1.770806908607483\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.70      0.36       143\n","         1.0       0.75      0.87      0.81       414\n","         2.0       0.97      0.80      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.65      0.79      0.68      2464\n","weighted avg       0.89      0.81      0.83      2464\n","\n","  Macro F1: 0.682\n","1.726841926574707\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.66      0.38       143\n","         1.0       0.74      0.88      0.81       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.79      0.69      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.691\n","1.701043963432312\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.66      0.40       143\n","         1.0       0.76      0.86      0.80       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.79      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.700\n","1.8270279169082642\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.65      0.41       143\n","         1.0       0.74      0.89      0.81       414\n","         2.0       0.96      0.84      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.79      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.703\n","1.7578551769256592\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.65      0.43       143\n","         1.0       0.72      0.90      0.80       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.80      0.71      2464\n","weighted avg       0.88      0.84      0.85      2464\n","\n","  Macro F1: 0.709\n","1.9064794778823853\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.65      0.41       143\n","         1.0       0.74      0.90      0.81       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.79      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.703\n","1.8147579431533813\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.64      0.42       143\n","         1.0       0.72      0.89      0.80       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.79      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.703\n","2.0662899017333984\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.64      0.42       143\n","         1.0       0.69      0.91      0.78       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.79      0.70      2464\n","weighted avg       0.88      0.83      0.84      2464\n","\n","  Macro F1: 0.698\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.58      0.43       142\n","         1.0       0.80      0.89      0.84       413\n","         2.0       0.96      0.89      0.92      1909\n","\n","    accuracy                           0.87      2464\n","   macro avg       0.70      0.79      0.73      2464\n","weighted avg       0.90      0.87      0.88      2464\n","\n","0 500 {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}}}\n","2.6554722785949707\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00       143\n","         1.0       0.17      0.99      0.29       414\n","         2.0       0.86      0.01      0.03      1907\n","\n","    accuracy                           0.18      2464\n","   macro avg       0.34      0.33      0.10      2464\n","weighted avg       0.70      0.18      0.07      2464\n","\n","  Macro F1: 0.104\n","1.9825565814971924\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.15      0.81      0.25       143\n","         1.0       0.61      0.60      0.60       414\n","         2.0       0.96      0.64      0.77      1907\n","\n","    accuracy                           0.64      2464\n","   macro avg       0.57      0.68      0.54      2464\n","weighted avg       0.85      0.64      0.71      2464\n","\n","  Macro F1: 0.539\n","1.961724877357483\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.57      0.40       143\n","         1.0       0.78      0.81      0.80       414\n","         2.0       0.95      0.88      0.91      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.75      0.70      2464\n","weighted avg       0.88      0.85      0.86      2464\n","\n","  Macro F1: 0.703\n","2.6279475688934326\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.74      0.39       143\n","         1.0       0.84      0.69      0.76       414\n","         2.0       0.95      0.85      0.90      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.76      0.68      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.682\n","2.309061288833618\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.57      0.35       143\n","         1.0       0.78      0.84      0.81       414\n","         2.0       0.95      0.85      0.90      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.75      0.69      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.687\n","1.9972805976867676\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.75      0.34       143\n","         1.0       0.76      0.88      0.82       414\n","         2.0       0.97      0.76      0.85      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.65      0.80      0.67      2464\n","weighted avg       0.89      0.78      0.82      2464\n","\n","  Macro F1: 0.669\n","1.4867295026779175\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.62      0.39       143\n","         1.0       0.71      0.89      0.79       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.78      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.689\n","2.2177951335906982\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.64      0.37       143\n","         1.0       0.67      0.93      0.78       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.63      0.78      0.67      2464\n","weighted avg       0.88      0.80      0.82      2464\n","\n","  Macro F1: 0.671\n","1.9518086910247803\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.59      0.38       143\n","         1.0       0.74      0.88      0.81       414\n","         2.0       0.96      0.84      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.77      0.69      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.692\n","1.9056048393249512\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.64      0.41       143\n","         1.0       0.79      0.86      0.82       414\n","         2.0       0.96      0.86      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.79      0.71      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.711\n","2.5873665809631348\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.56      0.43       143\n","         1.0       0.76      0.90      0.82       414\n","         2.0       0.96      0.88      0.92      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.69      0.78      0.72      2464\n","weighted avg       0.89      0.86      0.87      2464\n","\n","  Macro F1: 0.722\n","1.885090947151184\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.60      0.41       143\n","         1.0       0.76      0.90      0.82       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.67      0.78      0.71      2464\n","weighted avg       0.89      0.85      0.86      2464\n","\n","  Macro F1: 0.711\n","2.6927311420440674\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.67      0.38       143\n","         1.0       0.75      0.88      0.81       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.79      0.69      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.692\n","1.1600730419158936\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.69      0.35       143\n","         1.0       0.73      0.87      0.79       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.64      0.78      0.67      2464\n","weighted avg       0.88      0.79      0.82      2464\n","\n","  Macro F1: 0.667\n","1.7036042213439941\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.65      0.40       143\n","         1.0       0.71      0.89      0.79       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.79      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.691\n","1.9203135967254639\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.61      0.42       143\n","         1.0       0.69      0.89      0.78       414\n","         2.0       0.96      0.84      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.78      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.697\n","2.4421801567077637\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.62      0.39       143\n","         1.0       0.75      0.88      0.81       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.78      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.699\n","1.8789578676223755\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.64      0.40       143\n","         1.0       0.72      0.89      0.79       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.78      0.69      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.694\n","1.738494634628296\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.62      0.40       143\n","         1.0       0.71      0.90      0.79       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.65      0.78      0.69      2464\n","weighted avg       0.88      0.83      0.84      2464\n","\n","  Macro F1: 0.692\n","2.3215949535369873\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.64      0.40       143\n","         1.0       0.72      0.89      0.80       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.79      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.693\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.56      0.43       142\n","         1.0       0.78      0.91      0.84       413\n","         2.0       0.96      0.88      0.92      1909\n","\n","    accuracy                           0.87      2464\n","   macro avg       0.70      0.78      0.73      2464\n","weighted avg       0.90      0.87      0.88      2464\n","\n","0.001 500 {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}}}\n","2.3677337169647217\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.22      0.10       143\n","         1.0       0.16      0.77      0.27       414\n","         2.0       1.00      0.00      0.00      1907\n","\n","    accuracy                           0.14      2464\n","   macro avg       0.41      0.33      0.12      2464\n","weighted avg       0.80      0.14      0.05      2464\n","\n","  Macro F1: 0.122\n","2.6121230125427246\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.18      0.39      0.24       143\n","         1.0       0.59      0.53      0.56       414\n","         2.0       0.89      0.83      0.86      1907\n","\n","    accuracy                           0.75      2464\n","   macro avg       0.55      0.58      0.55      2464\n","weighted avg       0.80      0.75      0.77      2464\n","\n","  Macro F1: 0.555\n","2.043187141418457\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.52      0.41       143\n","         1.0       0.63      0.89      0.74       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.64      0.75      0.68      2464\n","weighted avg       0.87      0.82      0.84      2464\n","\n","  Macro F1: 0.680\n","2.4114913940429688\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.71      0.31       143\n","         1.0       0.71      0.89      0.79       414\n","         2.0       0.97      0.72      0.83      1907\n","\n","    accuracy                           0.75      2464\n","   macro avg       0.62      0.77      0.64      2464\n","weighted avg       0.88      0.75      0.79      2464\n","\n","  Macro F1: 0.641\n","2.935290575027466\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.72      0.36       143\n","         1.0       0.74      0.87      0.80       414\n","         2.0       0.97      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.65      0.79      0.68      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.676\n","1.9858014583587646\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.83      0.33       143\n","         1.0       0.81      0.79      0.80       414\n","         2.0       0.97      0.75      0.84      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.66      0.79      0.66      2464\n","weighted avg       0.90      0.76      0.81      2464\n","\n","  Macro F1: 0.656\n","1.712162733078003\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.64      0.41       143\n","         1.0       0.72      0.89      0.80       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.78      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.699\n","2.631784439086914\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.66      0.37       143\n","         1.0       0.79      0.83      0.81       414\n","         2.0       0.95      0.83      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.77      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.686\n","1.8305798768997192\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.55      0.39       143\n","         1.0       0.71      0.89      0.79       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.65      0.76      0.69      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.690\n","2.124896764755249\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.80      0.33       143\n","         1.0       0.78      0.79      0.78       414\n","         2.0       0.96      0.76      0.85      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.65      0.78      0.65      2464\n","weighted avg       0.89      0.76      0.81      2464\n","\n","  Macro F1: 0.653\n","2.2534024715423584\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.71      0.38       143\n","         1.0       0.79      0.81      0.80       414\n","         2.0       0.95      0.82      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.78      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.686\n","1.9868969917297363\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.67      0.40       143\n","         1.0       0.79      0.82      0.81       414\n","         2.0       0.95      0.84      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.78      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.699\n","1.908027172088623\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.66      0.41       143\n","         1.0       0.76      0.85      0.80       414\n","         2.0       0.95      0.84      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.78      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.700\n","2.1364707946777344\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.61      0.38       143\n","         1.0       0.73      0.90      0.80       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.78      0.69      2464\n","weighted avg       0.88      0.83      0.84      2464\n","\n","  Macro F1: 0.692\n","1.95281982421875\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.74      0.39       143\n","         1.0       0.78      0.84      0.81       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.80      0.69      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.694\n","2.0159718990325928\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.64      0.43       143\n","         1.0       0.77      0.88      0.82       414\n","         2.0       0.96      0.86      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.79      0.72      2464\n","weighted avg       0.89      0.85      0.86      2464\n","\n","  Macro F1: 0.717\n","2.406712293624878\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.71      0.41       143\n","         1.0       0.68      0.88      0.77       414\n","         2.0       0.97      0.80      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.64      0.80      0.68      2464\n","weighted avg       0.88      0.81      0.83      2464\n","\n","  Macro F1: 0.684\n","2.0204858779907227\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.70      0.41       143\n","         1.0       0.73      0.88      0.80       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.80      0.70      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.698\n","1.7486616373062134\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.67      0.43       143\n","         1.0       0.72      0.88      0.79       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.80      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.705\n","1.9293169975280762\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.70      0.42       143\n","         1.0       0.74      0.86      0.80       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.80      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.703\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.55      0.40       142\n","         1.0       0.79      0.90      0.84       413\n","         2.0       0.96      0.87      0.91      1909\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.69      0.78      0.72      2464\n","weighted avg       0.89      0.86      0.87      2464\n","\n","0.01 500 {'f1': 0.7175360001046203, 'acc': 0.859577922077922}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}}}\n","2.5184824466705322\n","### Validation Set Stats\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.81      0.11       143\n","         1.0       0.12      0.16      0.14       414\n","         2.0       0.00      0.00      0.00      1907\n","\n","    accuracy                           0.07      2464\n","   macro avg       0.06      0.32      0.08      2464\n","weighted avg       0.02      0.07      0.03      2464\n","\n","  Macro F1: 0.083\n","2.4920740127563477\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.58      0.37       143\n","         1.0       0.54      0.75      0.62       414\n","         2.0       0.91      0.76      0.83      1907\n","\n","    accuracy                           0.75      2464\n","   macro avg       0.57      0.70      0.61      2464\n","weighted avg       0.81      0.75      0.77      2464\n","\n","  Macro F1: 0.608\n","2.2841482162475586\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.77      0.34       143\n","         1.0       0.73      0.82      0.77       414\n","         2.0       0.96      0.75      0.84      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.64      0.78      0.65      2464\n","weighted avg       0.88      0.76      0.80      2464\n","\n","  Macro F1: 0.651\n","2.2942442893981934\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.62      0.40       143\n","         1.0       0.66      0.95      0.78       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.64      0.79      0.69      2464\n","weighted avg       0.88      0.81      0.83      2464\n","\n","  Macro F1: 0.685\n","1.8005331754684448\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.68      0.45       143\n","         1.0       0.64      0.92      0.75       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.80      0.70      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.697\n","1.9182758331298828\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.70      0.39       143\n","         1.0       0.71      0.92      0.80       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.65      0.81      0.69      2464\n","weighted avg       0.89      0.81      0.83      2464\n","\n","  Macro F1: 0.690\n","1.7886093854904175\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.71      0.37       143\n","         1.0       0.71      0.90      0.79       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.64      0.80      0.68      2464\n","weighted avg       0.88      0.79      0.82      2464\n","\n","  Macro F1: 0.675\n","1.8589318990707397\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.69      0.42       143\n","         1.0       0.74      0.90      0.81       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.80      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.706\n","2.379760503768921\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.36      0.63      0.46       143\n","         1.0       0.71      0.91      0.80       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.80      0.72      2464\n","weighted avg       0.88      0.85      0.86      2464\n","\n","  Macro F1: 0.720\n","2.1040291786193848\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.76      0.36       143\n","         1.0       0.78      0.87      0.83       414\n","         2.0       0.97      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.80      0.68      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.682\n","1.937273621559143\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.64      0.39       143\n","         1.0       0.77      0.86      0.81       414\n","         2.0       0.96      0.84      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.78      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.699\n","2.4412007331848145\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.66      0.42       143\n","         1.0       0.68      0.92      0.78       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.79      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.695\n","1.8260588645935059\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.71      0.38       143\n","         1.0       0.83      0.83      0.83       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.79      0.70      2464\n","weighted avg       0.89      0.82      0.85      2464\n","\n","  Macro F1: 0.697\n","1.9935665130615234\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.63      0.41       143\n","         1.0       0.70      0.91      0.79       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.79      0.70      2464\n","weighted avg       0.88      0.83      0.84      2464\n","\n","  Macro F1: 0.698\n","1.821202278137207\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.77      0.35       143\n","         1.0       0.73      0.87      0.80       414\n","         2.0       0.97      0.76      0.85      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.64      0.80      0.66      2464\n","weighted avg       0.89      0.78      0.81      2464\n","\n","  Macro F1: 0.664\n","1.972438931465149\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.68      0.42       143\n","         1.0       0.75      0.87      0.81       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.80      0.71      2464\n","weighted avg       0.89      0.84      0.85      2464\n","\n","  Macro F1: 0.708\n","2.0010077953338623\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.71      0.41       143\n","         1.0       0.75      0.89      0.81       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.703\n","1.783311367034912\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.67      0.40       143\n","         1.0       0.70      0.90      0.79       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.79      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.690\n","1.9246374368667603\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.63      0.43       143\n","         1.0       0.69      0.91      0.79       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.79      0.70      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.704\n","2.3577706813812256\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.64      0.44       143\n","         1.0       0.74      0.89      0.81       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.80      0.72      2464\n","weighted avg       0.89      0.85      0.86      2464\n","\n","  Macro F1: 0.720\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.58      0.43       142\n","         1.0       0.73      0.91      0.81       413\n","         2.0       0.96      0.86      0.91      1909\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.78      0.72      2464\n","weighted avg       0.89      0.85      0.87      2464\n","\n","0.1 500 {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}}}\n","2.9901812076568604\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.17      0.01      0.01       143\n","         1.0       0.15      0.55      0.23       414\n","         2.0       0.73      0.36      0.48      1907\n","\n","    accuracy                           0.37      2464\n","   macro avg       0.35      0.30      0.24      2464\n","weighted avg       0.60      0.37      0.41      2464\n","\n","  Macro F1: 0.243\n","2.393989324569702\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.18      0.64      0.28       143\n","         1.0       0.87      0.24      0.38       414\n","         2.0       0.84      0.81      0.83      1907\n","\n","    accuracy                           0.71      2464\n","   macro avg       0.63      0.56      0.50      2464\n","weighted avg       0.81      0.71      0.72      2464\n","\n","  Macro F1: 0.496\n","2.167283058166504\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.46      0.48      0.47       143\n","         1.0       0.80      0.76      0.78       414\n","         2.0       0.92      0.93      0.92      1907\n","\n","    accuracy                           0.87      2464\n","   macro avg       0.73      0.72      0.72      2464\n","weighted avg       0.87      0.87      0.87      2464\n","\n","  Macro F1: 0.723\n","1.7370071411132812\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.72      0.40       143\n","         1.0       0.76      0.86      0.81       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.80      0.70      2464\n","weighted avg       0.89      0.82      0.85      2464\n","\n","  Macro F1: 0.700\n","2.235595941543579\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.72      0.39       143\n","         1.0       0.72      0.92      0.81       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.81      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.694\n","2.416170358657837\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.76      0.33       143\n","         1.0       0.81      0.79      0.80       414\n","         2.0       0.96      0.77      0.85      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.66      0.77      0.66      2464\n","weighted avg       0.89      0.77      0.81      2464\n","\n","  Macro F1: 0.660\n","2.0225110054016113\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.63      0.43       143\n","         1.0       0.71      0.93      0.80       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.80      0.71      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.706\n","2.1630125045776367\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.68      0.42       143\n","         1.0       0.76      0.90      0.82       414\n","         2.0       0.96      0.84      0.89      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.80      0.71      2464\n","weighted avg       0.89      0.84      0.85      2464\n","\n","  Macro F1: 0.713\n","2.0654807090759277\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.75      0.35       143\n","         1.0       0.72      0.87      0.78       414\n","         2.0       0.97      0.76      0.85      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.64      0.79      0.66      2464\n","weighted avg       0.89      0.78      0.81      2464\n","\n","  Macro F1: 0.662\n","1.7143293619155884\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.62      0.41       143\n","         1.0       0.79      0.86      0.82       414\n","         2.0       0.95      0.86      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.78      0.71      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.710\n","1.6356241703033447\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.71      0.40       143\n","         1.0       0.77      0.87      0.82       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.80      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.703\n","1.864454746246338\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.79      0.39       143\n","         1.0       0.75      0.87      0.80       414\n","         2.0       0.98      0.79      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.82      0.69      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.687\n","1.9734091758728027\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.71      0.38       143\n","         1.0       0.74      0.86      0.80       414\n","         2.0       0.96      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.79      0.69      2464\n","weighted avg       0.88      0.81      0.83      2464\n","\n","  Macro F1: 0.686\n","2.4274113178253174\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.75      0.40       143\n","         1.0       0.82      0.85      0.84       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.81      0.71      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.706\n","1.671753168106079\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.67      0.42       143\n","         1.0       0.78      0.87      0.83       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.80      0.71      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.713\n","2.103163957595825\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.69      0.41       143\n","         1.0       0.78      0.87      0.82       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.80      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.708\n","1.6371195316314697\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.72      0.38       143\n","         1.0       0.75      0.89      0.81       414\n","         2.0       0.96      0.80      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.80      0.69      2464\n","weighted avg       0.89      0.81      0.83      2464\n","\n","  Macro F1: 0.690\n","1.9978610277175903\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.66      0.43       143\n","         1.0       0.77      0.89      0.82       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.80      0.72      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.716\n","1.8071492910385132\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.67      0.43       143\n","         1.0       0.76      0.90      0.82       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.81      0.72      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.717\n","1.7008271217346191\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.69      0.42       143\n","         1.0       0.74      0.90      0.82       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.710\n","              precision    recall  f1-score   support\n","\n","         0.0       0.37      0.39      0.38       142\n","         1.0       0.83      0.80      0.82       413\n","         2.0       0.92      0.93      0.92      1909\n","\n","    accuracy                           0.87      2464\n","   macro avg       0.71      0.70      0.71      2464\n","weighted avg       0.88      0.87      0.87      2464\n","\n","1 500 {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}}}\n","2.913698196411133\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.01      0.01       143\n","         1.0       0.17      0.99      0.29       414\n","         2.0       0.89      0.03      0.06      1907\n","\n","    accuracy                           0.19      2464\n","   macro avg       0.37      0.34      0.12      2464\n","weighted avg       0.72      0.19      0.09      2464\n","\n","  Macro F1: 0.121\n","2.460451364517212\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.61      0.31       143\n","         1.0       0.57      0.72      0.64       414\n","         2.0       0.93      0.74      0.82      1907\n","\n","    accuracy                           0.73      2464\n","   macro avg       0.57      0.69      0.59      2464\n","weighted avg       0.83      0.73      0.76      2464\n","\n","  Macro F1: 0.591\n","2.1965231895446777\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.52      0.41       143\n","         1.0       0.61      0.92      0.73       414\n","         2.0       0.96      0.82      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.64      0.75      0.67      2464\n","weighted avg       0.86      0.81      0.83      2464\n","\n","  Macro F1: 0.674\n","1.4981074333190918\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.72      0.33       143\n","         1.0       0.68      0.90      0.78       414\n","         2.0       0.97      0.73      0.83      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.62      0.78      0.65      2464\n","weighted avg       0.88      0.76      0.80      2464\n","\n","  Macro F1: 0.646\n","2.1307308673858643\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.66      0.38       143\n","         1.0       0.64      0.93      0.76       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.63      0.79      0.67      2464\n","weighted avg       0.88      0.79      0.81      2464\n","\n","  Macro F1: 0.667\n","2.3492302894592285\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.67      0.42       143\n","         1.0       0.74      0.89      0.81       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.80      0.71      2464\n","weighted avg       0.89      0.84      0.85      2464\n","\n","  Macro F1: 0.708\n","2.353533983230591\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.64      0.41       143\n","         1.0       0.74      0.89      0.81       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.79      0.70      2464\n","weighted avg       0.89      0.84      0.85      2464\n","\n","  Macro F1: 0.705\n","1.7873172760009766\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.74      0.35       143\n","         1.0       0.78      0.88      0.83       414\n","         2.0       0.96      0.78      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.66      0.80      0.68      2464\n","weighted avg       0.89      0.79      0.83      2464\n","\n","  Macro F1: 0.679\n","1.8815512657165527\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.69      0.40       143\n","         1.0       0.68      0.93      0.79       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.65      0.80      0.69      2464\n","weighted avg       0.88      0.81      0.83      2464\n","\n","  Macro F1: 0.685\n","2.0844767093658447\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.66      0.39       143\n","         1.0       0.72      0.90      0.80       414\n","         2.0       0.96      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.79      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.692\n","2.1321656703948975\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.66      0.40       143\n","         1.0       0.78      0.87      0.82       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.79      0.71      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.708\n","2.1897928714752197\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.71      0.40       143\n","         1.0       0.76      0.89      0.82       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.80      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.702\n","1.8014681339263916\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.74      0.39       143\n","         1.0       0.81      0.84      0.82       414\n","         2.0       0.96      0.82      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.80      0.70      2464\n","weighted avg       0.89      0.82      0.85      2464\n","\n","  Macro F1: 0.698\n","1.9111835956573486\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.74      0.40       143\n","         1.0       0.75      0.88      0.81       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.699\n","1.3888018131256104\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.69      0.39       143\n","         1.0       0.75      0.83      0.79       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.78      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.688\n","1.7479496002197266\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.71      0.39       143\n","         1.0       0.81      0.81      0.81       414\n","         2.0       0.95      0.84      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.79      0.70      2464\n","weighted avg       0.89      0.82      0.85      2464\n","\n","  Macro F1: 0.698\n","1.5722870826721191\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.69      0.40       143\n","         1.0       0.75      0.87      0.81       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.80      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.700\n","1.9752683639526367\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.73      0.39       143\n","         1.0       0.75      0.87      0.80       414\n","         2.0       0.96      0.81      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.80      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.690\n","1.9647332429885864\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.64      0.41       143\n","         1.0       0.70      0.89      0.79       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.79      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.692\n","2.2482006549835205\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.66      0.40       143\n","         1.0       0.71      0.89      0.79       414\n","         2.0       0.96      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.79      0.69      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.691\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.63      0.40       142\n","         1.0       0.82      0.87      0.84       413\n","         2.0       0.96      0.86      0.91      1909\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.79      0.72      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","10 500 {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}}}\n","2.9026126861572266\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.17      0.09       143\n","         1.0       0.00      0.00      0.00       414\n","         2.0       0.78      0.84      0.81      1907\n","\n","    accuracy                           0.66      2464\n","   macro avg       0.28      0.34      0.30      2464\n","weighted avg       0.61      0.66      0.63      2464\n","\n","  Macro F1: 0.300\n","2.2649598121643066\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.16      0.76      0.27       143\n","         1.0       0.41      0.77      0.54       414\n","         2.0       0.95      0.52      0.67      1907\n","\n","    accuracy                           0.57      2464\n","   macro avg       0.51      0.68      0.49      2464\n","weighted avg       0.82      0.57      0.62      2464\n","\n","  Macro F1: 0.493\n","2.252704620361328\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.69      0.35       143\n","         1.0       0.70      0.83      0.76       414\n","         2.0       0.96      0.78      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.63      0.77      0.66      2464\n","weighted avg       0.88      0.79      0.82      2464\n","\n","  Macro F1: 0.658\n","2.0281991958618164\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.78      0.33       143\n","         1.0       0.63      0.93      0.75       414\n","         2.0       0.98      0.68      0.80      1907\n","\n","    accuracy                           0.73      2464\n","   macro avg       0.61      0.80      0.63      2464\n","weighted avg       0.87      0.73      0.76      2464\n","\n","  Macro F1: 0.627\n","2.613248109817505\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.76      0.41       143\n","         1.0       0.74      0.89      0.81       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.82      0.70      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.697\n","2.4270241260528564\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.70      0.43       143\n","         1.0       0.78      0.87      0.82       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.81      0.72      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.717\n","1.6077873706817627\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.76      0.37       143\n","         1.0       0.78      0.89      0.83       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.81      0.69      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.686\n","1.9202860593795776\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.76      0.37       143\n","         1.0       0.81      0.82      0.82       414\n","         2.0       0.96      0.81      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.79      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.687\n","2.5088138580322266\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.77      0.35       143\n","         1.0       0.77      0.86      0.81       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.66      0.80      0.68      2464\n","weighted avg       0.89      0.79      0.82      2464\n","\n","  Macro F1: 0.675\n","1.9499046802520752\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.73      0.41       143\n","         1.0       0.77      0.87      0.82       414\n","         2.0       0.96      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.705\n","2.0310723781585693\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.69      0.42       143\n","         1.0       0.67      0.91      0.77       414\n","         2.0       0.96      0.80      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.65      0.80      0.69      2464\n","weighted avg       0.88      0.81      0.83      2464\n","\n","  Macro F1: 0.688\n","2.0149357318878174\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.68      0.45       143\n","         1.0       0.66      0.92      0.77       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.80      0.70      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.701\n","2.5670523643493652\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.36      0.58      0.44       143\n","         1.0       0.69      0.93      0.79       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.67      0.78      0.71      2464\n","weighted avg       0.88      0.84      0.85      2464\n","\n","  Macro F1: 0.710\n","2.1447038650512695\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.68      0.45       143\n","         1.0       0.74      0.89      0.81       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.80      0.72      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.719\n","1.5821824073791504\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.66      0.43       143\n","         1.0       0.71      0.90      0.79       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.80      0.71      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.706\n","1.9255633354187012\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.69      0.44       143\n","         1.0       0.80      0.85      0.82       414\n","         2.0       0.95      0.86      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.80      0.72      2464\n","weighted avg       0.89      0.85      0.86      2464\n","\n","  Macro F1: 0.722\n","1.8006881475448608\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.66      0.43       143\n","         1.0       0.72      0.90      0.80       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.80      0.71      2464\n","weighted avg       0.88      0.83      0.85      2464\n","\n","  Macro F1: 0.707\n","2.040179967880249\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.70      0.43       143\n","         1.0       0.72      0.90      0.80       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.707\n","2.294368028640747\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.69      0.44       143\n","         1.0       0.75      0.89      0.82       414\n","         2.0       0.96      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.81      0.72      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.719\n","1.587508201599121\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.67      0.43       143\n","         1.0       0.77      0.88      0.82       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.80      0.72      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.716\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.62      0.40       142\n","         1.0       0.85      0.85      0.85       413\n","         2.0       0.95      0.88      0.91      1909\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.70      0.78      0.72      2464\n","weighted avg       0.90      0.86      0.87      2464\n","\n","100 500 {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}}}\n","3000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["3.1720821857452393\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.07      0.05      0.06       143\n","         1.0       0.17      0.97      0.29       414\n","         2.0       0.80      0.00      0.01      1907\n","\n","    accuracy                           0.17      2464\n","   macro avg       0.35      0.34      0.12      2464\n","weighted avg       0.65      0.17      0.06      2464\n","\n","  Macro F1: 0.118\n","2.063913345336914\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.19      0.63      0.29       143\n","         1.0       0.46      0.70      0.55       414\n","         2.0       0.91      0.65      0.76      1907\n","\n","    accuracy                           0.66      2464\n","   macro avg       0.52      0.66      0.54      2464\n","weighted avg       0.79      0.66      0.70      2464\n","\n","  Macro F1: 0.535\n","1.871433973312378\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.55      0.41       143\n","         1.0       0.71      0.91      0.80       414\n","         2.0       0.96      0.86      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.67      0.77      0.70      2464\n","weighted avg       0.88      0.85      0.86      2464\n","\n","  Macro F1: 0.705\n","2.2741620540618896\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.63      0.45       143\n","         1.0       0.78      0.84      0.81       414\n","         2.0       0.96      0.88      0.92      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.70      0.78      0.73      2464\n","weighted avg       0.89      0.86      0.87      2464\n","\n","  Macro F1: 0.727\n","1.6843745708465576\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.38      0.62      0.47       143\n","         1.0       0.76      0.92      0.83       414\n","         2.0       0.96      0.88      0.92      1907\n","\n","    accuracy                           0.87      2464\n","   macro avg       0.70      0.80      0.74      2464\n","weighted avg       0.89      0.87      0.88      2464\n","\n","  Macro F1: 0.740\n","2.090762138366699\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.76      0.44       143\n","         1.0       0.79      0.90      0.84       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.69      0.83      0.73      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.728\n","1.933011531829834\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.80      0.35       143\n","         1.0       0.83      0.86      0.84       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.67      0.81      0.68      2464\n","weighted avg       0.90      0.79      0.83      2464\n","\n","  Macro F1: 0.685\n","1.8798342943191528\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.83      0.35       143\n","         1.0       0.73      0.93      0.82       414\n","         2.0       0.98      0.72      0.83      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.65      0.83      0.67      2464\n","weighted avg       0.90      0.76      0.80      2464\n","\n","  Macro F1: 0.667\n","1.8995404243469238\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.82      0.37       143\n","         1.0       0.80      0.89      0.84       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.67      0.83      0.69      2464\n","weighted avg       0.90      0.79      0.83      2464\n","\n","  Macro F1: 0.690\n","2.166189670562744\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.78      0.39       143\n","         1.0       0.85      0.88      0.86       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.69      0.82      0.71      2464\n","weighted avg       0.91      0.82      0.85      2464\n","\n","  Macro F1: 0.712\n","2.5269196033477783\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.72      0.43       143\n","         1.0       0.78      0.92      0.85       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.69      0.83      0.73      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.726\n","1.8528554439544678\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.77      0.37       143\n","         1.0       0.80      0.92      0.86       414\n","         2.0       0.97      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.80      0.84      2464\n","\n","  Macro F1: 0.696\n","1.7593975067138672\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.74      0.39       143\n","         1.0       0.75      0.93      0.83       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.699\n","2.1441564559936523\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.70      0.46       143\n","         1.0       0.79      0.91      0.85       414\n","         2.0       0.97      0.86      0.91      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.70      0.82      0.74      2464\n","weighted avg       0.90      0.86      0.87      2464\n","\n","  Macro F1: 0.741\n","1.525910496711731\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.77      0.34       143\n","         1.0       0.82      0.90      0.86       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.67      0.81      0.69      2464\n","weighted avg       0.90      0.79      0.83      2464\n","\n","  Macro F1: 0.685\n","2.1641664505004883\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.74      0.40       143\n","         1.0       0.78      0.93      0.85       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.709\n","1.7714133262634277\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.76      0.40       143\n","         1.0       0.83      0.90      0.86       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.69      0.83      0.72      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.716\n","2.182842493057251\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.74      0.39       143\n","         1.0       0.79      0.91      0.84       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.82      0.71      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.706\n","2.035830020904541\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.69      0.45       143\n","         1.0       0.74      0.93      0.83       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.82      0.73      2464\n","weighted avg       0.89      0.85      0.86      2464\n","\n","  Macro F1: 0.725\n","1.6448663473129272\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.75      0.40       143\n","         1.0       0.81      0.91      0.85       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.713\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.65      0.42       142\n","         1.0       0.79      0.91      0.85       413\n","         2.0       0.96      0.85      0.90      1909\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.80      0.72      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","0 1000 {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}, 1000: {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}}}\n","2.863466501235962\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.01      0.02       143\n","         1.0       0.17      0.99      0.29       414\n","         2.0       0.84      0.01      0.02      1907\n","\n","    accuracy                           0.17      2464\n","   macro avg       0.36      0.34      0.11      2464\n","weighted avg       0.68      0.17      0.07      2464\n","\n","  Macro F1: 0.111\n","2.3469011783599854\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.17      0.43      0.24       143\n","         1.0       0.48      0.88      0.62       414\n","         2.0       0.94      0.66      0.78      1907\n","\n","    accuracy                           0.68      2464\n","   macro avg       0.53      0.66      0.55      2464\n","weighted avg       0.82      0.68      0.72      2464\n","\n","  Macro F1: 0.545\n","2.428223133087158\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.57      0.43       143\n","         1.0       0.40      0.97      0.57       414\n","         2.0       0.98      0.63      0.77      1907\n","\n","    accuracy                           0.68      2464\n","   macro avg       0.58      0.72      0.59      2464\n","weighted avg       0.85      0.68      0.71      2464\n","\n","  Macro F1: 0.589\n","2.3418350219726562\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.69      0.39       143\n","         1.0       0.76      0.89      0.82       414\n","         2.0       0.96      0.82      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.80      0.70      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.697\n","1.9827364683151245\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.64      0.44       143\n","         1.0       0.65      0.94      0.77       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.65      0.80      0.70      2464\n","weighted avg       0.88      0.82      0.84      2464\n","\n","  Macro F1: 0.696\n","2.5408935546875\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.70      0.40       143\n","         1.0       0.75      0.91      0.82       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.704\n","2.6446011066436768\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.77      0.43       143\n","         1.0       0.78      0.89      0.83       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.83      0.72      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.717\n","2.0235037803649902\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.70      0.38       143\n","         1.0       0.71      0.94      0.81       414\n","         2.0       0.97      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.65      0.81      0.69      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.685\n","1.9115943908691406\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.71      0.43       143\n","         1.0       0.83      0.88      0.86       414\n","         2.0       0.96      0.86      0.91      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.70      0.81      0.73      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","  Macro F1: 0.729\n","2.3373451232910156\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.77      0.39       143\n","         1.0       0.79      0.92      0.85       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.83      0.70      2464\n","weighted avg       0.90      0.82      0.84      2464\n","\n","  Macro F1: 0.704\n","2.63930082321167\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.67      0.40       143\n","         1.0       0.74      0.92      0.82       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.80      0.70      2464\n","weighted avg       0.89      0.82      0.85      2464\n","\n","  Macro F1: 0.700\n","2.6227660179138184\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.69      0.44       143\n","         1.0       0.76      0.93      0.83       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.82      0.72      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.722\n","2.1686835289001465\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.72      0.42       143\n","         1.0       0.78      0.91      0.84       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.82      0.72      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.718\n","2.2417056560516357\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.76      0.42       143\n","         1.0       0.78      0.89      0.83       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.715\n","1.654237985610962\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.78      0.37       143\n","         1.0       0.83      0.86      0.84       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.68      0.81      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.698\n","2.119961977005005\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.78      0.35       143\n","         1.0       0.84      0.84      0.84       414\n","         2.0       0.96      0.78      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.68      0.80      0.68      2464\n","weighted avg       0.90      0.79      0.83      2464\n","\n","  Macro F1: 0.683\n","1.8656662702560425\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.73      0.39       143\n","         1.0       0.85      0.85      0.85       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.69      0.80      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.707\n","2.1059956550598145\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.73      0.41       143\n","         1.0       0.78      0.90      0.84       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.709\n","1.6540642976760864\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.69      0.40       143\n","         1.0       0.77      0.92      0.84       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.709\n","1.700951337814331\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.69      0.42       143\n","         1.0       0.76      0.92      0.83       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.81      0.71      2464\n","weighted avg       0.89      0.84      0.85      2464\n","\n","  Macro F1: 0.714\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.66      0.40       142\n","         1.0       0.85      0.89      0.87       413\n","         2.0       0.96      0.86      0.91      1909\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.70      0.80      0.72      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","0.001 1000 {'f1': 0.7236906876741859, 'acc': 0.8506493506493507}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}, 1000: {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}, 1000: {'f1': 0.7236906876741859, 'acc': 0.8506493506493507}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}}}\n","2.725048065185547\n","### Validation Set Stats\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.98      0.11       143\n","         1.0       0.00      0.00      0.00       414\n","         2.0       0.81      0.02      0.04      1907\n","\n","    accuracy                           0.07      2464\n","   macro avg       0.29      0.33      0.05      2464\n","weighted avg       0.63      0.07      0.03      2464\n","\n","  Macro F1: 0.048\n","2.4699277877807617\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.25      0.23       143\n","         1.0       0.60      0.79      0.68       414\n","         2.0       0.92      0.84      0.88      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.58      0.63      0.60      2464\n","weighted avg       0.82      0.80      0.81      2464\n","\n","  Macro F1: 0.597\n","2.335071325302124\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.55      0.38       143\n","         1.0       0.70      0.91      0.79       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.65      0.76      0.69      2464\n","weighted avg       0.87      0.83      0.84      2464\n","\n","  Macro F1: 0.686\n","2.104702949523926\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.71      0.34       143\n","         1.0       0.64      0.95      0.77       414\n","         2.0       0.98      0.72      0.83      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.62      0.79      0.65      2464\n","weighted avg       0.88      0.76      0.79      2464\n","\n","  Macro F1: 0.646\n","1.857728362083435\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.34      0.63      0.44       143\n","         1.0       0.79      0.86      0.82       414\n","         2.0       0.96      0.87      0.91      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.69      0.79      0.73      2464\n","weighted avg       0.89      0.86      0.87      2464\n","\n","  Macro F1: 0.725\n","1.7880908250808716\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.69      0.41       143\n","         1.0       0.71      0.92      0.80       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.81      0.70      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.697\n","1.9208961725234985\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.73      0.36       143\n","         1.0       0.71      0.92      0.80       414\n","         2.0       0.97      0.76      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.64      0.80      0.67      2464\n","weighted avg       0.89      0.79      0.82      2464\n","\n","  Macro F1: 0.674\n","2.4051425457000732\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.74      0.34       143\n","         1.0       0.82      0.88      0.85       414\n","         2.0       0.96      0.78      0.86      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.67      0.80      0.69      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.687\n","1.953433871269226\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.74      0.31       143\n","         1.0       0.75      0.93      0.83       414\n","         2.0       0.97      0.72      0.83      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.64      0.80      0.66      2464\n","weighted avg       0.89      0.76      0.80      2464\n","\n","  Macro F1: 0.655\n","1.6725516319274902\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.18      0.80      0.29       143\n","         1.0       0.82      0.86      0.84       414\n","         2.0       0.97      0.70      0.82      1907\n","\n","    accuracy                           0.74      2464\n","   macro avg       0.65      0.79      0.65      2464\n","weighted avg       0.90      0.74      0.79      2464\n","\n","  Macro F1: 0.649\n","2.261643171310425\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.69      0.35       143\n","         1.0       0.79      0.92      0.85       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.80      0.69      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.687\n","1.9445852041244507\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.61      0.44       143\n","         1.0       0.80      0.88      0.84       414\n","         2.0       0.95      0.88      0.92      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.70      0.79      0.73      2464\n","weighted avg       0.89      0.86      0.88      2464\n","\n","  Macro F1: 0.732\n","1.8626996278762817\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.75      0.38       143\n","         1.0       0.78      0.91      0.84       414\n","         2.0       0.97      0.79      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.698\n","2.569674015045166\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.76      0.36       143\n","         1.0       0.80      0.89      0.85       414\n","         2.0       0.97      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.67      0.81      0.69      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.690\n","2.1349294185638428\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.73      0.40       143\n","         1.0       0.80      0.91      0.85       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.72      2464\n","weighted avg       0.90      0.83      0.86      2464\n","\n","  Macro F1: 0.716\n","1.8903660774230957\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.78      0.38       143\n","         1.0       0.79      0.87      0.83       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.695\n","2.06148099899292\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.73      0.39       143\n","         1.0       0.79      0.91      0.84       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.703\n","1.8734949827194214\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.74      0.35       143\n","         1.0       0.80      0.90      0.85       414\n","         2.0       0.97      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.67      0.81      0.69      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.688\n","1.9672987461090088\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.76      0.37       143\n","         1.0       0.80      0.90      0.85       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.698\n","2.419339179992676\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.73      0.41       143\n","         1.0       0.79      0.91      0.84       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.714\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.57      0.42       142\n","         1.0       0.83      0.90      0.86       413\n","         2.0       0.96      0.89      0.92      1909\n","\n","    accuracy                           0.87      2464\n","   macro avg       0.71      0.78      0.73      2464\n","weighted avg       0.90      0.87      0.88      2464\n","\n","0.01 1000 {'f1': 0.733289566634423, 'acc': 0.8709415584415584}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}, 1000: {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}, 1000: {'f1': 0.7236906876741859, 'acc': 0.8506493506493507}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}, 1000: {'f1': 0.733289566634423, 'acc': 0.8709415584415584}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}}}\n","2.3823492527008057\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.80      0.11       143\n","         1.0       0.11      0.03      0.04       414\n","         2.0       0.84      0.18      0.30      1907\n","\n","    accuracy                           0.19      2464\n","   macro avg       0.34      0.34      0.15      2464\n","weighted avg       0.67      0.19      0.24      2464\n","\n","  Macro F1: 0.150\n","2.4643359184265137\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.16      0.70      0.26       143\n","         1.0       0.38      0.84      0.53       414\n","         2.0       0.96      0.47      0.63      1907\n","\n","    accuracy                           0.54      2464\n","   macro avg       0.50      0.67      0.47      2464\n","weighted avg       0.81      0.54      0.59      2464\n","\n","  Macro F1: 0.470\n","2.121555805206299\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.70      0.38       143\n","         1.0       0.77      0.78      0.78       414\n","         2.0       0.95      0.83      0.89      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.77      0.68      2464\n","weighted avg       0.88      0.81      0.84      2464\n","\n","  Macro F1: 0.681\n","2.25297212600708\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.44      0.49      0.46       143\n","         1.0       0.67      0.93      0.78       414\n","         2.0       0.96      0.87      0.91      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.69      0.76      0.72      2464\n","weighted avg       0.88      0.86      0.86      2464\n","\n","  Macro F1: 0.718\n","2.028409004211426\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.73      0.36       143\n","         1.0       0.75      0.91      0.82       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.65      0.80      0.68      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.681\n","2.163621664047241\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.76      0.38       143\n","         1.0       0.76      0.92      0.83       414\n","         2.0       0.98      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.82      0.69      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.693\n","1.9214600324630737\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.70      0.43       143\n","         1.0       0.75      0.92      0.83       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.82      0.72      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.718\n","2.2047135829925537\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.78      0.36       143\n","         1.0       0.77      0.91      0.83       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.66      0.82      0.68      2464\n","weighted avg       0.90      0.79      0.82      2464\n","\n","  Macro F1: 0.683\n","2.092089891433716\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.82      0.33       143\n","         1.0       0.81      0.89      0.85       414\n","         2.0       0.98      0.74      0.84      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.66      0.82      0.67      2464\n","weighted avg       0.90      0.77      0.81      2464\n","\n","  Macro F1: 0.674\n","2.057267904281616\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.78      0.42       143\n","         1.0       0.78      0.91      0.84       414\n","         2.0       0.97      0.81      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.83      0.72      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.715\n","1.4579774141311646\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.78      0.44       143\n","         1.0       0.82      0.90      0.86       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.70      0.84      0.73      2464\n","weighted avg       0.91      0.84      0.87      2464\n","\n","  Macro F1: 0.731\n","2.2947731018066406\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.71      0.39       143\n","         1.0       0.77      0.91      0.84       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.89      0.82      0.85      2464\n","\n","  Macro F1: 0.704\n","2.123961925506592\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.76      0.44       143\n","         1.0       0.81      0.90      0.85       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.70      0.83      0.73      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","  Macro F1: 0.731\n","1.7536522150039673\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.76      0.38       143\n","         1.0       0.68      0.92      0.78       414\n","         2.0       0.97      0.76      0.85      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.64      0.81      0.67      2464\n","weighted avg       0.88      0.78      0.81      2464\n","\n","  Macro F1: 0.671\n","2.157834529876709\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.71      0.43       143\n","         1.0       0.75      0.92      0.83       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.82      0.72      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.715\n","1.9365642070770264\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.78      0.39       143\n","         1.0       0.75      0.91      0.82       414\n","         2.0       0.97      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.82      0.69      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.694\n","2.0423882007598877\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.67      0.46       143\n","         1.0       0.74      0.92      0.82       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.81      0.73      2464\n","weighted avg       0.89      0.85      0.86      2464\n","\n","  Macro F1: 0.728\n","1.8774969577789307\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.73      0.44       143\n","         1.0       0.77      0.91      0.84       414\n","         2.0       0.97      0.83      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.69      0.83      0.72      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.724\n","2.178359270095825\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.72      0.43       143\n","         1.0       0.78      0.91      0.84       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.69      0.82      0.72      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.723\n","2.084782361984253\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.77      0.39       143\n","         1.0       0.77      0.91      0.83       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.701\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.67      0.40       142\n","         1.0       0.82      0.90      0.86       413\n","         2.0       0.97      0.85      0.91      1909\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.81      0.72      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","0.1 1000 {'f1': 0.7234303129210463, 'acc': 0.8498376623376623}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}, 1000: {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}, 1000: {'f1': 0.7236906876741859, 'acc': 0.8506493506493507}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}, 1000: {'f1': 0.733289566634423, 'acc': 0.8709415584415584}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}, 1000: {'f1': 0.7234303129210463, 'acc': 0.8498376623376623}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}}}\n","2.7817180156707764\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.06      0.91      0.12       143\n","         1.0       0.00      0.00      0.00       414\n","         2.0       0.80      0.15      0.26      1907\n","\n","    accuracy                           0.17      2464\n","   macro avg       0.29      0.35      0.12      2464\n","weighted avg       0.62      0.17      0.21      2464\n","\n","  Macro F1: 0.124\n","2.7318472862243652\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.61      0.31       143\n","         1.0       0.50      0.80      0.61       414\n","         2.0       0.93      0.67      0.78      1907\n","\n","    accuracy                           0.69      2464\n","   macro avg       0.54      0.69      0.57      2464\n","weighted avg       0.81      0.69      0.72      2464\n","\n","  Macro F1: 0.566\n","3.0560851097106934\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.16      0.78      0.27       143\n","         1.0       0.68      0.83      0.74       414\n","         2.0       0.97      0.64      0.77      1907\n","\n","    accuracy                           0.68      2464\n","   macro avg       0.60      0.75      0.59      2464\n","weighted avg       0.88      0.68      0.74      2464\n","\n","  Macro F1: 0.595\n","2.4746668338775635\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.66      0.33       143\n","         1.0       0.76      0.88      0.82       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.65      0.78      0.67      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.675\n","2.366891384124756\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.71      0.38       143\n","         1.0       0.76      0.93      0.84       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.66      0.81      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.697\n","2.2029623985290527\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.39      0.60      0.47       143\n","         1.0       0.68      0.96      0.80       414\n","         2.0       0.97      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.68      0.80      0.72      2464\n","weighted avg       0.89      0.85      0.86      2464\n","\n","  Macro F1: 0.724\n","1.7439972162246704\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.81      0.33       143\n","         1.0       0.83      0.86      0.85       414\n","         2.0       0.97      0.75      0.85      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.67      0.81      0.68      2464\n","weighted avg       0.90      0.77      0.82      2464\n","\n","  Macro F1: 0.676\n","1.959425449371338\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.80      0.37       143\n","         1.0       0.82      0.89      0.86       414\n","         2.0       0.97      0.78      0.86      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.68      0.82      0.70      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.695\n","1.8679412603378296\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.70      0.41       143\n","         1.0       0.77      0.93      0.84       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.713\n","2.5851120948791504\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.79      0.39       143\n","         1.0       0.74      0.91      0.82       414\n","         2.0       0.98      0.78      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.83      0.69      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.691\n","1.6249290704727173\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.76      0.37       143\n","         1.0       0.70      0.93      0.80       414\n","         2.0       0.98      0.75      0.85      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.64      0.82      0.68      2464\n","weighted avg       0.89      0.79      0.82      2464\n","\n","  Macro F1: 0.676\n","2.196485757827759\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.68      0.44       143\n","         1.0       0.78      0.92      0.84       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.81      0.73      2464\n","weighted avg       0.90      0.85      0.86      2464\n","\n","  Macro F1: 0.726\n","2.05647349357605\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.72      0.42       143\n","         1.0       0.73      0.92      0.82       414\n","         2.0       0.97      0.81      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.82      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.708\n","2.0880653858184814\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.76      0.39       143\n","         1.0       0.78      0.91      0.84       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.82      0.71      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.706\n","1.4965157508850098\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.83      0.33       143\n","         1.0       0.80      0.89      0.84       414\n","         2.0       0.97      0.74      0.84      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.66      0.82      0.67      2464\n","weighted avg       0.90      0.77      0.81      2464\n","\n","  Macro F1: 0.672\n","1.548112154006958\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.70      0.44       143\n","         1.0       0.77      0.92      0.84       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.82      0.73      2464\n","weighted avg       0.90      0.85      0.86      2464\n","\n","  Macro F1: 0.726\n","2.25810170173645\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.79      0.35       143\n","         1.0       0.79      0.91      0.85       414\n","         2.0       0.98      0.76      0.85      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.66      0.82      0.68      2464\n","weighted avg       0.90      0.79      0.82      2464\n","\n","  Macro F1: 0.683\n","1.8930511474609375\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.78      0.35       143\n","         1.0       0.79      0.91      0.85       414\n","         2.0       0.98      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.67      0.82      0.69      2464\n","weighted avg       0.90      0.79      0.83      2464\n","\n","  Macro F1: 0.686\n","2.0957798957824707\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.74      0.40       143\n","         1.0       0.80      0.91      0.85       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.86      2464\n","\n","  Macro F1: 0.714\n","2.0512051582336426\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.68      0.41       143\n","         1.0       0.77      0.92      0.84       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.81      0.71      2464\n","weighted avg       0.89      0.84      0.86      2464\n","\n","  Macro F1: 0.715\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.63      0.41       142\n","         1.0       0.79      0.92      0.85       413\n","         2.0       0.97      0.86      0.91      1909\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.80      0.72      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","1 1000 {'f1': 0.7227337843577075, 'acc': 0.8530844155844156}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}, 1000: {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}, 1000: {'f1': 0.7236906876741859, 'acc': 0.8506493506493507}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}, 1000: {'f1': 0.733289566634423, 'acc': 0.8709415584415584}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}, 1000: {'f1': 0.7234303129210463, 'acc': 0.8498376623376623}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}, 1000: {'f1': 0.7227337843577075, 'acc': 0.8530844155844156}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}}}\n","2.2383627891540527\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.05      0.02      0.03       143\n","         1.0       0.23      0.28      0.25       414\n","         2.0       0.79      0.79      0.79      1907\n","\n","    accuracy                           0.66      2464\n","   macro avg       0.36      0.36      0.36      2464\n","weighted avg       0.65      0.66      0.66      2464\n","\n","  Macro F1: 0.357\n","2.80365252494812\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.27      0.27       143\n","         1.0       0.55      0.76      0.64       414\n","         2.0       0.91      0.84      0.87      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.58      0.62      0.60      2464\n","weighted avg       0.81      0.79      0.80      2464\n","\n","  Macro F1: 0.596\n","2.11505126953125\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.73      0.33       143\n","         1.0       0.77      0.85      0.81       414\n","         2.0       0.96      0.77      0.86      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.65      0.78      0.66      2464\n","weighted avg       0.89      0.78      0.82      2464\n","\n","  Macro F1: 0.664\n","2.223069667816162\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.70      0.35       143\n","         1.0       0.72      0.92      0.81       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.64      0.80      0.67      2464\n","weighted avg       0.89      0.79      0.82      2464\n","\n","  Macro F1: 0.672\n","2.1262576580047607\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.66      0.40       143\n","         1.0       0.71      0.95      0.81       414\n","         2.0       0.98      0.81      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.66      0.81      0.70      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.701\n","1.7327589988708496\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.66      0.44       143\n","         1.0       0.80      0.87      0.83       414\n","         2.0       0.96      0.87      0.91      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.70      0.80      0.73      2464\n","weighted avg       0.90      0.86      0.87      2464\n","\n","  Macro F1: 0.730\n","2.009389877319336\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.75      0.38       143\n","         1.0       0.78      0.91      0.84       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.697\n","2.199401617050171\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.74      0.39       143\n","         1.0       0.79      0.92      0.85       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.709\n","1.8621772527694702\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.76      0.42       143\n","         1.0       0.80      0.89      0.84       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.69      0.83      0.72      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.719\n","1.8735010623931885\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.85      0.36       143\n","         1.0       0.82      0.89      0.86       414\n","         2.0       0.98      0.76      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.68      0.83      0.69      2464\n","weighted avg       0.91      0.79      0.83      2464\n","\n","  Macro F1: 0.691\n","1.821323037147522\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.70      0.42       143\n","         1.0       0.77      0.92      0.84       414\n","         2.0       0.97      0.83      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.68      0.82      0.72      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.717\n","2.139751672744751\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.72      0.42       143\n","         1.0       0.82      0.89      0.85       414\n","         2.0       0.97      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.70      0.82      0.73      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","  Macro F1: 0.726\n","2.057424306869507\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.78      0.38       143\n","         1.0       0.81      0.89      0.85       414\n","         2.0       0.97      0.79      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.68      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.700\n","2.1686909198760986\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.79      0.38       143\n","         1.0       0.80      0.90      0.85       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.80      0.84      2464\n","\n","  Macro F1: 0.697\n","2.1110663414001465\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.77      0.38       143\n","         1.0       0.80      0.90      0.85       414\n","         2.0       0.97      0.80      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.68      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.703\n","1.715637445449829\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.77      0.38       143\n","         1.0       0.75      0.92      0.82       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.82      0.69      2464\n","weighted avg       0.89      0.80      0.83      2464\n","\n","  Macro F1: 0.688\n","2.091956853866577\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.70      0.40       143\n","         1.0       0.75      0.92      0.82       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.66      0.81      0.70      2464\n","weighted avg       0.89      0.82      0.84      2464\n","\n","  Macro F1: 0.701\n","2.280632495880127\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.72      0.40       143\n","         1.0       0.79      0.90      0.84       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.82      0.71      2464\n","weighted avg       0.90      0.83      0.85      2464\n","\n","  Macro F1: 0.713\n","1.9081019163131714\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.73      0.38       143\n","         1.0       0.80      0.89      0.84       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.702\n","1.6875272989273071\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.69      0.40       143\n","         1.0       0.79      0.90      0.84       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.81      0.71      2464\n","weighted avg       0.90      0.83      0.86      2464\n","\n","  Macro F1: 0.711\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.61      0.42       142\n","         1.0       0.81      0.89      0.85       413\n","         2.0       0.96      0.88      0.92      1909\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.70      0.79      0.73      2464\n","weighted avg       0.90      0.86      0.88      2464\n","\n","10 1000 {'f1': 0.7268906385208997, 'acc': 0.8628246753246753}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}, 1000: {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}, 1000: {'f1': 0.7236906876741859, 'acc': 0.8506493506493507}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}, 1000: {'f1': 0.733289566634423, 'acc': 0.8709415584415584}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}, 1000: {'f1': 0.7234303129210463, 'acc': 0.8498376623376623}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}, 1000: {'f1': 0.7227337843577075, 'acc': 0.8530844155844156}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}, 1000: {'f1': 0.7268906385208997, 'acc': 0.8628246753246753}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}}}\n","2.6852056980133057\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.03      0.01      0.01       143\n","         1.0       0.50      0.00      0.00       414\n","         2.0       0.77      0.99      0.87      1907\n","\n","    accuracy                           0.76      2464\n","   macro avg       0.44      0.33      0.29      2464\n","weighted avg       0.68      0.76      0.67      2464\n","\n","  Macro F1: 0.294\n","2.180400848388672\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.57      0.34       143\n","         1.0       0.54      0.60      0.57       414\n","         2.0       0.90      0.79      0.84      1907\n","\n","    accuracy                           0.74      2464\n","   macro avg       0.56      0.65      0.58      2464\n","weighted avg       0.80      0.74      0.76      2464\n","\n","  Macro F1: 0.583\n","2.0733656883239746\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.21      0.71      0.32       143\n","         1.0       0.76      0.82      0.79       414\n","         2.0       0.95      0.76      0.85      1907\n","\n","    accuracy                           0.77      2464\n","   macro avg       0.64      0.76      0.65      2464\n","weighted avg       0.87      0.77      0.81      2464\n","\n","  Macro F1: 0.652\n","2.020918369293213\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.68      0.42       143\n","         1.0       0.72      0.91      0.81       414\n","         2.0       0.97      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.708\n","2.0927600860595703\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.78      0.36       143\n","         1.0       0.74      0.93      0.82       414\n","         2.0       0.98      0.76      0.85      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.65      0.82      0.68      2464\n","weighted avg       0.90      0.79      0.82      2464\n","\n","  Macro F1: 0.681\n","2.000356674194336\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.74      0.37       143\n","         1.0       0.76      0.91      0.83       414\n","         2.0       0.98      0.79      0.87      1907\n","\n","    accuracy                           0.80      2464\n","   macro avg       0.66      0.81      0.69      2464\n","weighted avg       0.90      0.80      0.83      2464\n","\n","  Macro F1: 0.689\n","1.9956499338150024\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.76      0.35       143\n","         1.0       0.80      0.90      0.85       414\n","         2.0       0.97      0.77      0.86      1907\n","\n","    accuracy                           0.79      2464\n","   macro avg       0.67      0.81      0.69      2464\n","weighted avg       0.90      0.79      0.83      2464\n","\n","  Macro F1: 0.686\n","2.458768844604492\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.76      0.38       143\n","         1.0       0.79      0.91      0.85       414\n","         2.0       0.97      0.79      0.88      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.82      0.70      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.702\n","1.7828694581985474\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.67      0.43       143\n","         1.0       0.80      0.91      0.85       414\n","         2.0       0.96      0.85      0.91      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.81      0.73      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","  Macro F1: 0.727\n","1.9425268173217773\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.66      0.45       143\n","         1.0       0.77      0.93      0.84       414\n","         2.0       0.97      0.86      0.91      1907\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.69      0.82      0.74      2464\n","weighted avg       0.90      0.86      0.87      2464\n","\n","  Macro F1: 0.736\n","1.8751020431518555\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.76      0.37       143\n","         1.0       0.80      0.88      0.84       414\n","         2.0       0.97      0.79      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.81      0.69      2464\n","weighted avg       0.90      0.81      0.84      2464\n","\n","  Macro F1: 0.694\n","2.1953961849212646\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.19      0.83      0.31       143\n","         1.0       0.82      0.88      0.85       414\n","         2.0       0.98      0.72      0.83      1907\n","\n","    accuracy                           0.75      2464\n","   macro avg       0.66      0.81      0.67      2464\n","weighted avg       0.90      0.75      0.80      2464\n","\n","  Macro F1: 0.665\n","2.0462143421173096\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.70      0.41       143\n","         1.0       0.81      0.91      0.85       414\n","         2.0       0.97      0.84      0.90      1907\n","\n","    accuracy                           0.84      2464\n","   macro avg       0.69      0.81      0.72      2464\n","weighted avg       0.90      0.84      0.86      2464\n","\n","  Macro F1: 0.720\n","2.4879934787750244\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.22      0.80      0.34       143\n","         1.0       0.83      0.88      0.85       414\n","         2.0       0.97      0.76      0.85      1907\n","\n","    accuracy                           0.78      2464\n","   macro avg       0.67      0.81      0.68      2464\n","weighted avg       0.90      0.78      0.82      2464\n","\n","  Macro F1: 0.683\n","2.1088554859161377\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.25      0.72      0.37       143\n","         1.0       0.80      0.90      0.85       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.67      0.81      0.70      2464\n","weighted avg       0.90      0.82      0.84      2464\n","\n","  Macro F1: 0.699\n","1.526566982269287\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.67      0.41       143\n","         1.0       0.82      0.90      0.86       414\n","         2.0       0.96      0.85      0.90      1907\n","\n","    accuracy                           0.85      2464\n","   macro avg       0.69      0.81      0.72      2464\n","weighted avg       0.90      0.85      0.87      2464\n","\n","  Macro F1: 0.724\n","1.992753505706787\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.26      0.73      0.38       143\n","         1.0       0.82      0.90      0.86       414\n","         2.0       0.97      0.81      0.88      1907\n","\n","    accuracy                           0.82      2464\n","   macro avg       0.68      0.81      0.71      2464\n","weighted avg       0.90      0.82      0.85      2464\n","\n","  Macro F1: 0.706\n","1.3187321424484253\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.71      0.36       143\n","         1.0       0.80      0.90      0.85       414\n","         2.0       0.96      0.79      0.87      1907\n","\n","    accuracy                           0.81      2464\n","   macro avg       0.67      0.80      0.69      2464\n","weighted avg       0.89      0.81      0.84      2464\n","\n","  Macro F1: 0.691\n","2.530001163482666\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.67      0.38       143\n","         1.0       0.80      0.90      0.84       414\n","         2.0       0.96      0.83      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.68      0.80      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.705\n","2.1862339973449707\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.70      0.40       143\n","         1.0       0.78      0.90      0.84       414\n","         2.0       0.97      0.82      0.89      1907\n","\n","    accuracy                           0.83      2464\n","   macro avg       0.67      0.81      0.71      2464\n","weighted avg       0.89      0.83      0.85      2464\n","\n","  Macro F1: 0.706\n","              precision    recall  f1-score   support\n","\n","         0.0       0.31      0.57      0.41       142\n","         1.0       0.80      0.93      0.86       413\n","         2.0       0.96      0.87      0.92      1909\n","\n","    accuracy                           0.86      2464\n","   macro avg       0.69      0.79      0.73      2464\n","weighted avg       0.90      0.86      0.88      2464\n","\n","100 1000 {'f1': 0.7271808161136207, 'acc': 0.8640422077922078}\n","{0: {20: {'f1': 0.4724063162610421, 'acc': 0.653814935064935}, 50: {'f1': 0.6966781486196286, 'acc': 0.8607954545454546}, 100: {'f1': 0.6994560955703489, 'acc': 0.849025974025974}, 200: {'f1': 0.6981743454486319, 'acc': 0.8474025974025974}, 300: {'f1': 0.682979325163021, 'acc': 0.8242694805194806}, 400: {'f1': 0.7197602354050515, 'acc': 0.8599837662337663}, 500: {'f1': 0.7319616752472644, 'acc': 0.8709415584415584}, 1000: {'f1': 0.7227270375183837, 'acc': 0.8506493506493507}}, 0.001: {20: {'f1': 0.5290244550770867, 'acc': 0.7280844155844156}, 50: {'f1': 0.5536191680332888, 'acc': 0.6956168831168831}, 100: {'f1': 0.6965855914130644, 'acc': 0.8534902597402597}, 200: {'f1': 0.7153478867791682, 'acc': 0.8668831168831169}, 300: {'f1': 0.693797652940542, 'acc': 0.838474025974026}, 400: {'f1': 0.711869499492687, 'acc': 0.8449675324675324}, 500: {'f1': 0.7294301424272888, 'acc': 0.8685064935064936}, 1000: {'f1': 0.7236906876741859, 'acc': 0.8506493506493507}}, 0.01: {20: {'f1': 0.5419629457447185, 'acc': 0.734172077922078}, 50: {'f1': 0.6592756247928662, 'acc': 0.8474025974025974}, 100: {'f1': 0.6681736121915353, 'acc': 0.827922077922078}, 200: {'f1': 0.697912682012837, 'acc': 0.8474025974025974}, 300: {'f1': 0.7104911136145983, 'acc': 0.859172077922078}, 400: {'f1': 0.7094638349290596, 'acc': 0.8534902597402597}, 500: {'f1': 0.7175360001046203, 'acc': 0.859577922077922}, 1000: {'f1': 0.733289566634423, 'acc': 0.8709415584415584}}, 0.1: {20: {'f1': 0.5554574503591243, 'acc': 0.7183441558441559}, 50: {'f1': 0.6456887001209626, 'acc': 0.846185064935065}, 100: {'f1': 0.704070280472704, 'acc': 0.8599837662337663}, 200: {'f1': 0.7157050098226568, 'acc': 0.8579545454545454}, 300: {'f1': 0.7053950098850833, 'acc': 0.8502435064935064}, 400: {'f1': 0.7115825413427807, 'acc': 0.8506493506493507}, 500: {'f1': 0.7166405311077332, 'acc': 0.8538961038961039}, 1000: {'f1': 0.7234303129210463, 'acc': 0.8498376623376623}}, 1: {20: {'f1': 0.5909485262051993, 'acc': 0.7999188311688312}, 50: {'f1': 0.6853283699431877, 'acc': 0.8526785714285714}, 100: {'f1': 0.6501960222942538, 'acc': 0.8275162337662337}, 200: {'f1': 0.7005107748611695, 'acc': 0.8502435064935064}, 300: {'f1': 0.7087542671135774, 'acc': 0.849025974025974}, 400: {'f1': 0.7204394605127162, 'acc': 0.8652597402597403}, 500: {'f1': 0.7069089413922113, 'acc': 0.8745941558441559}, 1000: {'f1': 0.7227337843577075, 'acc': 0.8530844155844156}}, 10: {20: {'f1': 0.5436974154697379, 'acc': 0.7012987012987013}, 50: {'f1': 0.6233393920415441, 'acc': 0.827922077922078}, 100: {'f1': 0.6979885380961438, 'acc': 0.8526785714285714}, 200: {'f1': 0.7086986779038981, 'acc': 0.8465909090909091}, 300: {'f1': 0.7249181844413415, 'acc': 0.8612012987012987}, 400: {'f1': 0.7154766568626489, 'acc': 0.8510551948051948}, 500: {'f1': 0.7179881614203145, 'acc': 0.8510551948051948}, 1000: {'f1': 0.7268906385208997, 'acc': 0.8628246753246753}}, 100: {20: {'f1': 0.6100873820311521, 'acc': 0.8181818181818182}, 50: {'f1': 0.5785763756554392, 'acc': 0.7512175324675324}, 100: {'f1': 0.6919402368293109, 'acc': 0.859577922077922}, 200: {'f1': 0.7049155686652536, 'acc': 0.8579545454545454}, 300: {'f1': 0.7068114222004577, 'acc': 0.8518668831168831}, 400: {'f1': 0.7024793978923826, 'acc': 0.8433441558441559}, 500: {'f1': 0.7218271436606836, 'acc': 0.8571428571428571}, 1000: {'f1': 0.7271808161136207, 'acc': 0.8640422077922078}}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BwsHsSmG0BXy","executionInfo":{"status":"ok","timestamp":1617451152969,"user_tz":-330,"elapsed":12462859,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":[""],"execution_count":27,"outputs":[]}]}